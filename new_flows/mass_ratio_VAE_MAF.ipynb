{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import MAF\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnd = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_RandD.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ROC':\n",
    "    dt_PureBkg = f_rnd.values\n",
    "else:\n",
    "    dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt_PureBkg[:,27]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg)\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "#total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_3),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(12, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 12),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = MAF(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 40\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 1\n",
    "Z_DIM = 2\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -114.5014 Time: 3.227 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -128.7571 Time: 3.204 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -135.3517 Time: 3.233 s\n",
      "Saving model!\n",
      "Epoch 4:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -137.2531 Time: 3.227 s\n",
      "Saving model!\n",
      "Epoch 5:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -138.5085 Time: 3.212 s\n",
      "Saving model!\n",
      "Epoch 6:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -137.8154 Time: 3.252 s\n",
      "Not saving model! Last saved: 5\n",
      "Epoch 7:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.6593 Time: 3.261 s\n",
      "Saving model!\n",
      "Epoch 8:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.5225 Time: 3.215 s\n",
      "Saving model!\n",
      "Epoch 9:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.4722 Time: 3.300 s\n",
      "Saving model!\n",
      "Epoch 10:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -140.6880 Time: 3.283 s\n",
      "Not saving model! Last saved: 9\n",
      "Epoch 11:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -143.4910 Time: 3.254 s\n",
      "Saving model!\n",
      "Epoch 12:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.5243 Time: 3.280 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 13:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -143.4235 Time: 3.232 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 14:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -144.2885 Time: 3.267 s\n",
      "Saving model!\n",
      "Epoch 15:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.5515 Time: 3.289 s\n",
      "Not saving model! Last saved: 14\n",
      "Epoch 16:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -143.5573 Time: 3.232 s\n",
      "Not saving model! Last saved: 14\n",
      "Epoch 17:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.3313 Time: 3.256 s\n",
      "Saving model!\n",
      "Epoch 18:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -143.7589 Time: 3.237 s\n",
      "Not saving model! Last saved: 17\n",
      "Epoch 19:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.2566 Time: 3.230 s\n",
      "Not saving model! Last saved: 17\n",
      "Epoch 20:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.8051 Time: 3.304 s\n",
      "Saving model!\n",
      "Epoch 21:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.1992 Time: 3.265 s\n",
      "Not saving model! Last saved: 20\n",
      "Epoch 22:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.4073 Time: 3.260 s\n",
      "Not saving model! Last saved: 20\n",
      "Epoch 23:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.8628 Time: 3.273 s\n",
      "Saving model!\n",
      "Epoch 24:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.5733 Time: 3.240 s\n",
      "Not saving model! Last saved: 23\n",
      "Epoch 25:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -144.4488 Time: 3.265 s\n",
      "Not saving model! Last saved: 23\n",
      "Epoch 26:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.4611 Time: 3.265 s\n",
      "Saving model!\n",
      "Epoch 27:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.2657 Time: 3.275 s\n",
      "Not saving model! Last saved: 26\n",
      "Epoch 28:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.7883 Time: 3.250 s\n",
      "Saving model!\n",
      "Epoch 29:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -145.4072 Time: 3.264 s\n",
      "Not saving model! Last saved: 28\n",
      "Epoch 30:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.2886 Time: 3.248 s\n",
      "Not saving model! Last saved: 28\n",
      "Epoch 31:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.2042 Time: 3.264 s\n",
      "Not saving model! Last saved: 28\n",
      "Epoch 32:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -147.0940 Time: 3.247 s\n",
      "Saving model!\n",
      "Epoch 33:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -143.6645 Time: 3.267 s\n",
      "Not saving model! Last saved: 32\n",
      "Epoch 34:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -144.4142 Time: 3.249 s\n",
      "Not saving model! Last saved: 32\n",
      "Epoch 35:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.3609 Time: 3.228 s\n",
      "Not saving model! Last saved: 32\n",
      "Epoch 36:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -146.7540 Time: 3.280 s\n",
      "Not saving model! Last saved: 32\n",
      "Patience Limit Reached\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "PATIENCE_COUNT = 0\n",
    "PATIENCE_LIMIT = 5\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        PATIENCE_COUNT = 0\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        if mode == 'ROC':\n",
    "            torch.save(model.state_dict(),\"/data/t3home000/spark/QUASAR/weights/bkg_vae_MAF_RND.h5\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_MAF_PureBkg.h5\")\n",
    "    else:\n",
    "        PATIENCE_COUNT += 1\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "        if PATIENCE_COUNT > 3:\n",
    "            print(\"Patience Limit Reached\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/data/t3home000/spark/QUASAR/weights/bkg_vae_MAF_RND.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass(inputstring):\n",
    "\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='background')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt_in):\n",
    "\n",
    "    #dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    #dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    #dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    #dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    #dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    #dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    #dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    #dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    #dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    #dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    #dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    #dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    #dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    #dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    #dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    #dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    #dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    #dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    #dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    #dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    #dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    #dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    #total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_3),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = get_loss(dt_PureBkg[bkg_idx])\n",
    "loss_sig = get_loss(dt_PureBkg[signal_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('MAF_bkgae_sigloss.npy',loss_sig)\n",
    "np.save('MAF_bkgae_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

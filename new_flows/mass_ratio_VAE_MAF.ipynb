{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import MAF\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")\n",
    "dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg)\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(22, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 22),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = MAF(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 20\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 4\n",
    "Z_DIM = 4\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -363.5361 Time: 8.289 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -391.9571 Time: 8.523 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -395.0602 Time: 8.306 s\n",
      "Saving model!\n",
      "Epoch 4:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-492db43c8262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcur_loss\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mBEST_LOSS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-413c918ac798>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbkgAE_test_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        torch.save(model.state_dict(), \"lhc_weights/bkg_vae_NF_MAF.h5\")\n",
    "    else:\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass(inputstring):\n",
    "\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAJQCAYAAAA32OjOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XuUXWWZ7/vvAwHCVQLEGpGkCRwDcr/sSkBBroqApIG9gw1bm4DsDgJe2B53g30OTavNaB2HoTbH1m4UNsHN4aoRClGJEGCwRSrhYrhDQAxp2CEQ5LIRugPP+WPNqqxKqipVSa1a6631/YxRY835znfN9VQtNT/fd75zRmYiSZKk1rdRswuQJEnS0BjcJEmSCmFwkyRJKoTBTZIkqRAGN0mSpEIY3CRJkgphcJMkSSqEwU2SJKkQBjdJkqRCjGt2AY2www475NSpU5tdhiRJ0jrdf//9L2fmxKH0HZPBberUqSxatKjZZUiSJK1TRPxhqH2dKpUkSSqEwU2SJKkQBjdJkqRCjMlr3CRJ0sD+/d//nWXLlvH22283u5S2Mn78eCZPnswmm2yy3ucwuEmS1GaWLVvG1ltvzdSpU4mIZpfTFjKTV155hWXLlrHzzjuv93mcKpUkqc28/fbbbL/99oa2URQRbL/99hs8ymlwkySpDRnaRt9I/M0NbpIkSYXwGjdJktpcV9fInm/mzHX3ee655zj++ON55JFH+rQffvjhXHLJJXR2dg7rM6+88koWLVrE9773vT7tp59+OscffzyzZs0a1vnW9MQTT3DGGWfwwAMPcPHFF/OVr3xlg863vgxukiRJ67Dddttx6aWX8rOf/aypdThVKkmSmmLVqlXMnj2bffbZh1mzZvHWW2/1OX722WfT2dnJnnvuyUUXXdTbvnDhQj7ykY+w7777MmPGDN54440+7/v5z3/Ohz/8YV5++WUAfv3rX/PRj36UXXfdlVtuuQWoLdA444wz2Hvvvdl///1ZsGABAN/+9rf57Gc/C8DDDz/MXnvtxVtvvcX73/9+pk+fvkG38hgJjrhJkqSmePLJJ7n88ss5+OCD+exnP8v3v//9PscvvvhitttuO959912OOuooFi9ezIc+9CH+4i/+guuuu47p06fz+uuvs/nmm/e+Z968eXz729/m1ltvZcKECUBtWvauu+7imWee4YgjjmDJkiX80z/9E1ALZ0888QRHH300Tz31FOeddx6HH3448+bN4+KLL+Zf/uVf2GKLLUbvj7IOBjdJktQUU6ZM4eCDDwbgM5/5DJdeemmf49dffz2XXXYZq1at4sUXX+Sxxx4jIpg0aRLTp08HYJtttuntv2DBAhYtWsRtt93Wp/1Tn/oUG220EdOmTWOXXXbhiSee4J577uELX/gCAB/60IfYaaedeOqpp9hnn3248sor2WeffTjrrLN662sVTpVKkqSmWPP2GPX7v//977nkkku4/fbbWbx4MZ/85Cd5++23ycwBb6uxyy678MYbb/DUU0+t83Myc8C6nn76abbaaiteeOGF4f5KDWdwkyRJTbF06VLuvfdeAK655hoOOeSQ3mOvv/46W265Je973/tYvnw5v/jFL4Da6NgLL7zAwoULAXjjjTdYtWoVADvttBM//elPOe2003j00Ud7z3XDDTfw3nvv8cwzz/Dss8+y2267ceihh3L11VcD8NRTT7F06VJ22203XnvtNb70pS9x991388orr3DjjTeOyt9iqJwqlSSpzQ3l9h2NsPvuuzN37lzOOusspk2bxtlnn01XdW+Sfffdl/33358999yTXXbZpXfKctNNN+W6667jC1/4An/605/YfPPN+fWvf917zt12242rr76ak08+ufdcu+22G4cddhjLly/nn//5nxk/fjznnHMOn/vc59h7770ZN24cV155JZttthlnn30255xzDrvuuiuXX345RxxxBIceeijvvfcenZ2dvP7662y00UZ897vf5bHHHuszJTsaYrChwlJ1dnbmokWLml2GJEkt6fHHH2f33Xdvdhltqb+/fUTcn5lDunGdU6WSJEmFMLhJkiQVwuAmSZJUCIObJElSIQxukiRJhTC4SZIkFcL7uEmS1O6q+52NmCHcGO65557j+OOP55FHHlnvj7nzzju55JJLeh8c30pOP/10jj/+eGbNmjWi53XEbYwb6f8uSpI0FmQm7733XrPLGDaDmyRJaopVq1Yxe/Zs9tlnH2bNmsVbb73F17/+daZPn85ee+3FnDlzep8pumTJEj72sY+x7777csABB/DMM8/0OdfChQvZf//9efbZZ1mxYgUf//jHOeCAAzjrrLPYaaedePnll3nuuefYfffdOeecczjggAN4/vnnueaaa9h7773Za6+9OP/883vPt9VWW/Vu33jjjZx++ulAbSTti1/8Ih/5yEfYZZddeh+JlZl8/vOfZ4899uCTn/wkL730UkP+ZgY3SZLUFE8++SRz5sxh8eLFbLPNNnz/+9/n85//PAsXLuSRRx7hT3/6U+806Kc//WnOPfdcfve73/Gb3/yGSZMm9Z7nN7/5DZ/73Oe46aab2GWXXfja177GkUceyQMPPMBJJ53E0qVL+3zmaaedxoMPPsgmm2zC+eefzx133MFDDz3EwoUL+dnPfrbOul988UXuuecebrnlFi644AIA5s2bx5NPPsnDDz/MD3/4Q37zm9+M8F+rxuAmSZKaYsqUKb3PIP3MZz7DPffcw4IFCzjwwAPZe++9ueOOO3j00Ud54403+Nd//VdOOukkAMaPH88WW2wB1B4hNWfOHLq6uvizP/szAO655x5OOeUUAI455hgmTJjQ+5k77bQTBx10EFAbpTv88MOZOHEi48aN49Of/jR33333Ous+8cQT2Wijjdhjjz1Yvnw5AHfffTennnoqG2+8MR/4wAc48sgjR+iv1JfBTZIkNUVErLV/zjnncOONN/Lwww/zV3/1V7z99tsM9lz1SZMmMX78eB588MHetsH6b7nllkPqV1/b22+/3efYZptt1u851vx9GsHgNka5KEGS1OqWLl3KvffeC8A111zDIYccAsAOO+zAm2++2Xv92DbbbMPkyZN7pzHfeecd3nrrLQC23XZbfv7zn/M3f/M33HnnnQAccsghXH/99QDcdtttvPrqq/1+/oEHHshdd93Fyy+/zLvvvss111zDYYcdBkBHRwePP/447733HvPmzVvn73LooYdy7bXX8u677/Liiy+yYMGC9fyrDM7bgbSJrq4hrc6WJLWjJv0DsfvuuzN37lzOOusspk2bxtlnn82rr77K3nvvzdSpU5k+fXpv3x//+MecddZZ/O3f/i2bbLIJN9xwQ++xjo4Ourq6OPbYY7niiiu46KKLOPXUU7nuuus47LDDmDRpEltvvTVvvvlmn8+fNGkS//AP/8ARRxxBZnLcccdxwgknAPDNb36T448/nilTprDXXnut9d41nXTSSdxxxx3svffe7Lrrrr0BcKTFYMOEpers7MxFixY1u4ym6glq9a9geJMk1a4L23333ZtdRsO88847bLzxxowbN457772Xs88+m4ceeqjZZQH9/+0j4v7M7BzK+x1xkyRJY8rSpUv51Kc+xXvvvcemm27KD3/4w2aXNGIMbmNUR7dzo5Kk9jRt2rQ+ixXGEhcnjEEuTJAkrctYvFSq1Y3E39zgNob1BDiDnCSp3vjx43nllVcMb6MoM3nllVcYP378Bp3HqdIxxpAmSVqXyZMns2zZMlasWNHsUtrK+PHjmTx58gadw+AmSVKb2WSTTdh5552bXYbWg1OlkiRJhTC4SZIkFcLgJkmSVAiDmyRJUiEMbmNYR7dLTCVJGksaGtwi4r9GxKMR8UhEXBMR4yNi54i4LyKejojrImLTqu9m1f6S6vjUuvN8tWp/MiI+0ciaJUmSWlXDgltE7Ah8EejMzL2AjYFTgG8B38nMacCrwJnVW84EXs3MDwLfqfoREXtU79sTOAb4fkRs3Ki6JUmSWlWjp0rHAZtHxDhgC+BF4Ejgxur4XODEavuEap/q+FEREVX7tZn5Tmb+HlgCzGhw3ZIkSS2nYcEtM/8VuARYSi2wvQbcD/wxM1dV3ZYBO1bbOwLPV+9dVfXfvr69n/f0iog5EbEoIhZ5J+jVvM5NkqSxo5FTpROojZbtDHwA2BI4tp+uPQ9KiwGODdTetyHzsszszMzOiRMnrl/RBat/1JVhTZKksamRU6UfA36fmSsy89+BnwIfAbatpk4BJgMvVNvLgCkA1fH3ASvr2/t5j4bJZ5lKklSuRga3pcBBEbFFda3aUcBjwAJgVtVnNnBTtX1ztU91/I7MzKr9lGrV6c7ANKC7gXVLkiS1pEZe43YftUUGDwAPV591GXA+8OWIWELtGrbLq7dcDmxftX8ZuKA6z6PA9dRC3y+BczPz3UbVPRY5dSpJ0tgwbt1d1l9mXgRctEbzs/SzKjQz3wZOHuA8FwMXj3iBbaSju4vlM2Y2uwxJkrQBfHJCG/I6N0mSymRwkyRJKoTBTZIkqRAGN0mSpEIY3CRJkgphcJMkSSqEwW0McbWoJEljm8FNkiSpEAa3McanJEiSNHYZ3CRJkgphcJMkSSqEwU2SJKkQBrc24vVvkiSVzeA2BgznNiCGN0mSymVwG0MMZZIkjW0GN0mSpEIY3NpQR3cX3Rc6OidJUmkMbpIkSYUwuEmSJBXC4CZJklQIg5skSVIhDG6FG8493EbyvZIkafQZ3CRJkgphcGtjHd1djrpJklQQg9sY4VMTJEka+wxukiRJhTC4tTlH6iRJKofBTZIkqRAGN0mSpEIY3CRJkgphcJMkSSqEwU2SJKkQ45pdgDaMq0IlSWofjrhJkiQVwuAmSZJUCIObJElSIQxukiRJhTC4Cbpc4CBJUgkMbgUzb0mS1F4MbpIkSYUwuEmSJBXC4CZJklQIg5vo7m52BZIkaSgMbgJc6CBJUgkMbpIkSYUwuEmSJBXC4CZJklQIg5skSVIhDG6SJEmFMLgJgI5ul5VKktTqDG6F8vYdkiS1H4ObJElSIQxukiRJhWhYcIuI3SLiobqf1yPivIjYLiLmR8TT1euEqn9ExKURsSQiFkfEAXXnml31fzoiZjeq5tJ4XZokSe2lYcEtM5/MzP0ycz/gPwBvAfOAC4DbM3MacHu1D3AsMK36mQP8ACAitgMuAg4EZgAX9YQ9SZKkdjJaU6VHAc9k5h+AE4C5Vftc4MRq+wTgqqz5LbBtREwCPgHMz8yVmfkqMB84ZpTqliRJahmjFdxOAa6ptjsy80WA6vX9VfuOwPN171lWtQ3U3kdEzImIRRGxaMWKFSNcviRJUvM1PLhFxKbAnwM3rKtrP205SHvfhszLMrMzMzsnTpw4/EIlSZJa3GiMuB0LPJCZy6v95dUUKNXrS1X7MmBK3fsmAy8M0q4G8P5wkiS1rtEIbqeyepoU4GagZ2XobOCmuvbTqtWlBwGvVVOpvwKOjogJ1aKEo6s2SZKktjKukSePiC2AjwNn1TV/E7g+Is4ElgInV+23AscBS6itQD0DIDNXRsQ3gIVVv69n5spG1i1JktSKGhrcMvMtYPs12l6htsp0zb4JnDvAea4ArmhEjZIkSaXwyQmSJEmFMLipV/eFrkyQJKmVGdwkSZIKYXCTJEkqhMFNkiSpEAY3SZKkQhjcJEmSCmFwkyRJKoTBTZIkqRAGN/XR0e293CRJalUGN62ly+wmSVJLMrhJkiQVwuAmSZJUCIOb1uJ1bpIktSaDmyRJUiEMbpIkSYUwuBXIVZ+SJLUng5skSVIhDG6SJEmFMLhJkiQVwuCm/nkhnSRJLcfgVijvtSZJUvsxuBXGgTBJktqXwU2SJKkQBjf1q7u72RVIkqQ1GdwkSZIKYXCTJEkqhMFNkiSpEAY3SZKkQhjcJEmSCmFwkyRJKoTBrUCj9dQEb/YrSVJrMbhJkiQVwuAmSZJUCIObJElSIQxuGtBoXUsnSZKGxuAmSZJUCIObJElSIQxukiRJhTC4SZIkFcLgVhBviCtJUnszuEmSJBXC4KZBOconSVLrMLhJkiQVwuCmQXkTXkmSWofBTZIkqRAGN0mSpEIY3CRJkgphcJMkSSqEwa0wLhaQJKl9GdwkSZIKYXCTJEkqhMFNkiSpEA0NbhGxbUTcGBFPRMTjEfHhiNguIuZHxNPV64Sqb0TEpRGxJCIWR8QBdeeZXfV/OiJmN7JmSZKkVtXoEbd/BH6ZmR8C9gUeBy4Abs/MacDt1T7AscC06mcO8AOAiNgOuAg4EJgBXNQT9iRJktpJw4JbRGwDHApcDpCZ/5aZfwROAOZW3eYCJ1bbJwBXZc1vgW0jYhLwCWB+Zq7MzFeB+cAxjapbkiSpVTVyxG0XYAXw3yPiwYj4UURsCXRk5osA1ev7q/47As/XvX9Z1TZQex8RMSciFkXEohUrVoz8byNJktRkjQxu44ADgB9k5v7A/2b1tGh/op+2HKS9b0PmZZnZmZmdEydOXJ96JUmSWlojg9syYFlm3lft30gtyC2vpkCpXl+q6z+l7v2TgRcGaZckSWorDQtumfm/gOcjYreq6SjgMeBmoGdl6Gzgpmr7ZuC0anXpQcBr1VTqr4CjI2JCtSjh6KpNkiSprYxr8Pm/AFwdEZsCzwJnUAuL10fEmcBS4OSq763AccAS4K2qL5m5MiK+ASys+n09M1c2uG7V6+qCmTObXYUkSW2vocEtMx8COvs5dFQ/fRM4d4DzXAFcMbLVaai6u2E5ZjdJkprNJydIkiQVwuAmSZJUCIObJElSIQxuBeno7mp2CZIkqYkMbpIkSYUwuEmSJBXC4CZJklQIg5uGrstr7CRJaiaDWyHMTJIkyeAmSZJUCIObJElSIQxukiRJhTC4SZIkFcLgpiHxqQ2SJDWfwU3D4/JWSZKaxuCmIevubnYFkiS1N4ObJElSIQxukiRJhTC4SZIkFcLgJkmSVAiDmyRJUiEMbpIkSYUwuEmSJBXC4FYA73krSZLA4CZJklQMg5skSVIhDG4aFh97JUlS8xjcJEmSCmFwK0RHtysUJElqdwY3SZKkQhjcNGzenkSSpOYwuEmSJBXC4KZh83o7SZKaw+AmSZJUCIObJElSIQxukiRJhTC4SZIkFcLgJkmSVAiDmyRJUiEMbpIkSYUwuGm9+PQESZJGn8FNkiSpEAY3SZKkQhjctF587JUkSaPP4CZJklQIg5skSVIhDG6SJEmFMLhJkiQVwuCm9efN3CRJGlUGN0mSpEIY3CRJkgphcCuA90yTJElgcJMkSSpGQ4NbRDwXEQ9HxEMRsahq2y4i5kfE09XrhKo9IuLSiFgSEYsj4oC688yu+j8dEbMbWbOGyQUKkiSNmtEYcTsiM/fLzM5q/wLg9sycBtxe7QMcC0yrfuYAP4Ba0AMuAg4EZgAX9YQ9SZKkdtKMqdITgLnV9lzgxLr2q7Lmt8C2ETEJ+AQwPzNXZuarwHzgmNEuWpIkqdkaHdwSuC0i7o+IOVVbR2a+CFC9vr9q3xF4vu69y6q2gdr7iIg5EbEoIhatWLFihH8NSZKk5hvX4PMfnJkvRMT7gfkR8cQgfaOfthykvW9D5mXAZQCdnZ1rHZckSSpdQ0fcMvOF6vUlYB61a9SWV1OgVK8vVd2XAVPq3j4ZeGGQdrWA7u5mVyBJUvtoWHCLiC0jYuuebeBo4BHgZqBnZehs4KZq+2bgtGp16UHAa9VU6q+AoyNiQrUo4eiqTZIkqa00cqq0A5gXET2f8/9l5i8jYiFwfUScCSwFTq763wocBywB3gLOAMjMlRHxDWBh1e/rmbmygXVLkiS1pIYFt8x8Fti3n/ZXgKP6aU/g3AHOdQVwxUjXKEmSVBKfnNDivL+tJEnqYXDTenNhgiRJo8vgJkmSVAiDmyRJUiEMbtpwXognSdKoMLhJkiQVwuAmSZJUCIObJElSIQxukiRJhTC4SZIkFcLg1sJcrClJkuoZ3CRJkgphcNMG89FXkiSNDoObJElSIQxuLa6j2wvdJElSjcFNkiSpEAY3jQyXwEqS1HAGN0mSpEIY3CRJkgoxpOAWEQcPpU2SJEmNM9QRt/93iG2SJElqkHGDHYyIDwMfASZGxJfrDm0DbNzIwiRJktTXukbcNgW2ohbwtq77eR2Y1djSVBxXlkqS1FCDjrhl5l3AXRFxZWb+YZRqkiRJUj8GDW51NouIy4Cp9e/JzCMbUZQkSZLWNtTgdgPwz8CPgHcbV44kSZIGMtTgtiozf9DQSiRJkjSood4OpCsizomISRGxXc9PQyuTJElSH0MdcZtdvf63urYEdhnZciRJkjSQIQW3zNy50YWobN3dMGNGs6uQJGlsG1Jwi4jT+mvPzKtGthxJkiQNZKhTpdPrtscDRwEPAAY3SZKkUTLUqdIv1O9HxPuAHzekIkmSJPVrqKtK1/QWMG0kC5EkSdLghnqNWxe1VaRQe7j87sD1jSpKkiRJaxvqNW6X1G2vAv6QmcsaUI9K19UFM2c2uwpJksakIU2VVg+bfwLYGpgA/Fsji1JNR3dXs0uQJEktZEjBLSI+BXQDJwOfAu6LiFmNLEySJEl9DXWq9P8CpmfmSwARMRH4NXBjowqTJElSX0NdVbpRT2irvDKM90qSJGkEDHXE7ZcR8Svgmmr/L4BbG1OSJEmS+jNocIuIDwIdmfnfIuI/AocAAdwLXD0K9UmSJKmyrunO7wJvAGTmTzPzy5n5X6mNtn230cVJkiRptXUFt6mZuXjNxsxcBExtSEUqWnd3syuQJGnsWldwGz/Isc1HshD11eUt3CRJ0hrWFdwWRsRfrdkYEWcC9zemJJXK0TZJkhprXatKzwPmRcSnWR3UOoFNgZMaWZgK5mOvJElqiEGDW2YuBz4SEUcAe1XNP8/MOxpemSRJkvoY0n3cMnMBsKDBtUiSJGkQPv1AkiSpEAY3SZKkQhjcJEmSCmFwkyRJKkTDg1tEbBwRD0bELdX+zhFxX0Q8HRHXRcSmVftm1f6S6vjUunN8tWp/MiI+0eiaJUmSWtFojLh9CXi8bv9bwHcycxrwKnBm1X4m8GpmfhD4TtWPiNgDOAXYEzgG+H5EbDwKdWtD+OgHSZJGXEODW0RMBj4J/KjaD+BI4Maqy1zgxGr7hGqf6vhRVf8TgGsz853M/D2wBJjRyLolSZJaUaNH3L4L/DXwXrW/PfDHzFxV7S8Ddqy2dwSeB6iOv1b1723v5z29ImJORCyKiEUrVqwY6d9DkiSp6RoW3CLieOClzKx/pmn00zXXcWyw96xuyLwsMzszs3PixInDrleSJKnVNXLE7WDgzyPiOeBaalOk3wW2jYieJzZMBl6otpcBUwCq4+8DVta39/MetSAfNi9JUmM0LLhl5lczc3JmTqW2uOCOzPw0tUdnzaq6zQZuqrZvrvapjt+RmVm1n1KtOt0ZmAYYDSRJUtsZ0rNKR9j5wLUR8ffAg8DlVfvlwI8jYgm1kbZTADLz0Yi4HngMWAWcm5nvjn7ZkiRJzTUqwS0z7wTurLafpZ9VoZn5NnDyAO+/GLi4cRWqIbq6YObMZlchSdKY4ZMTJEmSCmFwkyRJKoTBTQ3hylJJkkaewa1FdXT7yChJktSXwU0N46ibJEkjy+AmSZJUCIObJElSIQxukiRJhTC4taAu1yVIkqR+GNzUWKZQSZJGjMFNkiSpEAY3SZKkQhjcJEmSCmFwkyRJKoTBTZIkqRAGN0mSpEIY3CRJkgphcGtBHd3e+0ySJK3N4KaG6u5udgWSJI0dBjc1nk9PkCRpRBjcJEmSCmFwkyRJKoTBTZIkqRAGN0mSpEIY3CRJkgphcJMkSSqEwU2jw1uCSJK0wQxuajhvwitJ0sgwuEmSJBXC4KbR43SpJEkbxOAmSZJUCIObJElSIQxuGhUuUJAkacMZ3CRJkgphcJMkSSqEwU2SJKkQBrcW0xZ3zGiLX1KSpJFncNPoMrRJkrTeDG6SJEmFMLhJkiQVwuAmSZJUCIObRo034ZUkacMY3CRJkgphcJMkSSqEwU2SJKkQBrcW09E99u9z5rVukiStH4ObJElSIQxukiRJhTC4qTl89JUkScNmcNOo8vo2SZLWn8FNkiSpEAY3SZKkQjQsuEXE+IjojojfRcSjEfG1qn3niLgvIp6OiOsiYtOqfbNqf0l1fGrdub5atT8ZEZ9oVM2SJEmtrJEjbu8AR2bmvsB+wDERcRDwLeA7mTkNeBU4s+p/JvBqZn4Q+E7Vj4jYAzgF2BM4Bvh+RGzcwLolSZJaUsOCW9a8We1uUv0kcCRwY9U+Fzix2j6h2qc6flRERNV+bWa+k5m/B5YAMxpVtyRJUqtq6DVuEbFxRDwEvATMB54B/piZq6ouy4Adq+0dgecBquOvAdvXt/fzHkmSpLbR0OCWme9m5n7AZGqjZLv31616jQGODdTeR0TMiYhFEbFoxYoV61uyJElSyxqVVaWZ+UfgTuAgYNuIGFcdmgy8UG0vA6YAVMffB6ysb+/nPfWfcVlmdmZm58SJExvxa0iSJDVVI1eVToyIbavtzYGPAY8DC4BZVbfZwE3V9s3VPtXxOzIzq/ZTqlWnOwPTAG/jKkmS2k4jR9wmAQsiYjGwEJifmbcA5wNfjogl1K5hu7zqfzmwfdX+ZeACgMx8FLgeeAz4JXBuZr7bwLqbpu2eAtV2v7AkSRtm3Lq7rJ/MXAzs30/7s/SzKjQz3wZOHuBcFwMXj3SNkiRJJfHJCZIkSYUwuKkpfNi8JEnDZ3CTJEkqhMFNkiSpEAY3NZcrSyVJGjKDmyRJUiEMbpIkSYUwuEmSJBXC4Kam8ZYgkiQNj8FNkiSpEAa3FtLR3aYrLF1ZKknSkBjc1BoMb5IkrZPBTZIkqRAGN0mSpEIY3NR0ri6VJGloDG5qKkObJElDZ3CTJEkqhMFNrcOVpZIkDcrgJkmSVAiDmyRJUiEMbpIkSYUwuEmSJBXC4CZJklQIg5skSVIhDG6SJEmFMLhJkiQVwuCm1uJNeCVJGpDBrUWYVyRJ0roY3CRJkgphcFPL6O5udgWSJLU2g5taQp/Q5ryxJEn9MrhJkiQVwuAmSZJUCIObJEkiXkchAAARVUlEQVRSIQxukiRJhTC4SZIkFcLgJkmSVAiDm1qK93KTJGlgBjdJkqRCGNzUurwRryRJfRjcJEmSCmFwU2tytE2SpLUY3CRJkgphcJMkSSqEwa1FdHQ7NShJkgZncJMkSSqEwU2tzUUKkiT1Mrip5fj0BEmS+mdwU0syvEmStDaDmyRJUiEMbi3Ay7gkSdJQGNwkSZIKYXCTJEkqRMOCW0RMiYgFEfF4RDwaEV+q2reLiPkR8XT1OqFqj4i4NCKWRMTiiDig7lyzq/5PR8TsRtUsSZLUyho54rYK+D8zc3fgIODciNgDuAC4PTOnAbdX+wDHAtOqnznAD6AW9ICLgAOBGcBFPWFPbcKLACVJAhoY3DLzxcx8oNp+A3gc2BE4AZhbdZsLnFhtnwBclTW/BbaNiEnAJ4D5mbkyM18F5gPHNKpuSZKkVjUq17hFxFRgf+A+oCMzX4RauAPeX3XbEXi+7m3LqraB2tUGvJ+bJEmrNTy4RcRWwE+A8zLz9cG69tOWg7Sv+TlzImJRRCxasWLF+hXbJD5gXpIkDUVDg1tEbEIttF2dmT+tmpdXU6BUry9V7cuAKXVvnwy8MEh7H5l5WWZ2ZmbnxIkTR/YXUfN5nZskSQ1dVRrA5cDjmfntukM3Az0rQ2cDN9W1n1atLj0IeK2aSv0VcHRETKgWJRxdtWmMc5pUkqS+xjXw3AcDfwk8HBEPVW1/A3wTuD4izgSWAidXx24FjgOWAG8BZwBk5sqI+AawsOr39cxc2cC6JUmSWlLDgltm3kP/16cBHNVP/wTOHeBcVwBXjFx1kiRJ5fHJCZIkSYUwuKnlea2bJEk1BjeVxdWlkqQ2ZnBTOQxtkqQ2Z3CTJEkqhMGtyRxEkiRJQ2VwkyRJKoTBTZIkqRAGN5XH+WVJUpsyuKkI3stNkiSDmyRJUjEMbiqT06WSpDZkcFO5DG+SpDZjcFNRvNZNktTODG4qhqFNktTuDG6SJEmFMLg1WUe312lJkqShMbhJkiQVwuCm4nitmySpXRncVD5vCyJJahMGNxWpd9TN0CZJaiMGN0mSpEIY3CRJkgphcJMkSSqEwU2SJKkQBjcVy9uCSJLajcFNkiSpEAa3JvJOFpIkaTgMbhpbTMOSpDHM4KaxwcAmSWoDBjcVrc8CBcObJGmMM7ipeK4ulSS1C4ObJElSIQxukiRJhTC4aezxWjdJ0hhlcGuijm4DhiRJGjqDmyRJUiEMbhoTXFkqSWoHBjeNGd7TTZI01hncJEmSCmFwkyRJKoTBrUmcyZMkScNlcJMkSSqEwU2SJKkQBjeNKWvdFsQ5aUnSGDKu2QVII60nvM3A0CZJGlsccZMkSSqEwU3twSlTSdIYYHBT+zC8SZIKZ3DTmOXzSyVJY43BTWOfI22SpDHC4CZJklQIg5skSVIhGhbcIuKKiHgpIh6pa9suIuZHxNPV64SqPSLi0ohYEhGLI+KAuvfMrvo/HRGzG1XvaOvodvpuNHhDXknSWNLIEbcrgWPWaLsAuD0zpwG3V/sAxwLTqp85wA+gFvSAi4ADgRnART1hT5Ikqd00LLhl5t3AyjWaTwDmVttzgRPr2q/Kmt8C20bEJOATwPzMXJmZrwLzWTsMSuvkClNJ0lgw2te4dWTmiwDV6/ur9h2B5+v6LavaBmqXhszQJkkaK1plcUL005aDtK99gog5EbEoIhatWLFiRIvTGON1bpKkQo12cFteTYFSvb5UtS8DptT1mwy8MEj7WjLzsszszMzOiRMnjnjhkiRJzTbawe1moGdl6Gzgprr206rVpQcBr1VTqb8Cjo6ICdWihKOrNmnY+p0ydfRNklSQcY06cURcAxwO7BARy6itDv0mcH1EnAksBU6uut8KHAcsAd4CzgDIzJUR8Q1gYdXv65m55oKH4nR1QUezi5AkScVpWHDLzFMHOHRUP30TOHeA81wBXDGCpUm19DxzZrOrkCRpWFplcYI0alxlKkkqlcFNbcXQJkkqmcFNcoGCJKkQDbvGTWpl3d0wAwObJKksjrhJkiQVwuDWBB3djvS0gj7XuzldKkkqgMFNkiSpEAY3SZKkQhjc1PZ6p0x7pkudNpUktSiDm1TP0CZJamEGN7U1b8grSSqJwW2UOaDT2gxykqRW5g14JfoJbPUJ24fRS5JahCNukiRJhTC4SZIkFcLgJq2hu3sdU6eSJDWJwU0aKsObJKnJDG7SAFxhKklqNQY3aR26L6wbaXPUTZLURAa3UdbR7T/8Jel31M3wJklqEoObJElSIQxu0hB5zZskqdkMbtIQ9IS23vDmdKkkqQkMbtL66uoywEmSRpXBTRqmfm/Oa4CTJI0Cg5u0HurDm9e+SZJGi8FN2gB9QpujbpKkBjO4jSL/XR9bBrzHm1+0JKlBDG5SIxniJEkjaFyzC2gnPjVh7OoZfZsxo7Y9A79rSdLIc8RNaoB+V55KkrSBDG7SCFrns00NcJKkDWBwkxpkzRDXfWE/Ac4gJ0kaBoOb1GBrBjizmiRpfRncpAbqb+q0d5GKU6iSpGEyuI0S/11ub2s9pL6e/+GQJA2RwU1qAgOcJGl9eB+3UeI93NSfNQPcDLroYiYzZ9Y1dnXRt0GS1K4ccZOaZKCH03d0d6296rT+1ZE5SWpbjrhJLaT+WrjlgONskqR6jrhJLWqt6XVH2iSp7TniJrWwta6Bm1G1X9hV2545c3Wg8zo4SRrzHHEbBQ6UaCTVh7nuC7tW73v9mySNeQa3UeCKUo2UPqFtje3enwsHmGI11ElS8Qxu0hjV1TVIiJMkFclr3KSxqKuLjjWmVKF2jdya18d1d7N6X5LU0hxxk8agwaZUe605+tbVtXqEzuvlJKklGdwazX/81KJ6rolba3tdCx7qrpnzP96SNLoMbg020N3xpWYayn8u+xud6wl19dfO1Yc3g5wkNZbXuEkaUJ/w1s/q6J4V093dsHzGzN79Lmrby2fMZCY+a1WSRoojbpLWy5qjdvUhrme7N8h1rV7l2n3h6inW7gu7Br+2rp8hPEf1JLWzyMxm1zDiOjs7c9GiRc0uo3fFnqTh6R2pY3VAnPGNmatXx36j7xMjhvLwiK4uHP2T1JIi4v7M7BxSX4Nb46x1Dy1Jo27GjNrULdRGAHsC4IwZ9H8rlK5Bwl3dsX67DfZeSRrAmAxuEXEM8I/AxsCPMvObA/U1uEnaED2hbs22Hj3H1ryGr/vCrt5r/XpHBQcLej0HqIXL0RgRNFtKrWfMBbeI2Bh4Cvg4sAxYCJyamY/1178VgpuhTWpv/YW/Hr3hbpA+PUGx/nhveJw5s8//xtRPIy+fMbOnS+/lGj0Bs2fksf54z0KSnvP06J1+HixMmgKlETEWg9uHgb/LzE9U+18FyMx/6K9/s4OboU1Su+sJp/WrjevVh9Y1p6/r39/TVn+efkdEv7F61LP+M+pHQ3vO23P9ZP3q555R0n4DaxVw15xRh9XT733Ur6DpL9gOEni7L+znfGu+p7/3r3mh5xBC9bqm+zckl5vph2csBrdZwDGZ+V+q/b8EDszMz/fXv5nBzdAmSVJrGej/QAylT79BeoQNJ7iVch+36KetT+KMiDnAnGr3zYh4suFVwQ7Ay6PwORo6v5PW5PfSevxOWpPfS6v5+1H5TnYaasdSgtsyYErd/mTghfoOmXkZcNloFhURi4aakDU6/E5ak99L6/E7aU1+L62n1b6TUm7AuxCYFhE7R8SmwCnAzU2uSZIkaVQVMeKWmasi4vPAr6jdDuSKzHy0yWVJkiSNqiKCG0Bm3grc2uw61jCqU7MaEr+T1uT30nr8TlqT30vraanvpIhVpZIkSSrnGjdJkqS2Z3BbDxFxTEQ8GRFLIuKCZtcjiIgrIuKliHik2bWoJiKmRMSCiHg8Ih6NiC81uyZBRIyPiO6I+F31vXyt2TWpJiI2jogHI+KWZteimoh4LiIejoiHIqL5z9LEqdJhG+7jtzQ6IuJQ4E3gqszcq9n1CCJiEjApMx+IiK2B+4ET/e9Kc0VEAFtm5psRsQlwD/ClzPxtk0trexHxZaAT2CYzj292PaoFN6AzM1vm3nqOuA3fDGBJZj6bmf8GXAuc0OSa2l5m3g2sbHYdWi0zX8zMB6rtN4DHgR2bW5Wy5s1qd5Pqx/8H32QRMRn4JPCjZtei1mZwG74dgefr9pfhP0bSoCJiKrA/cF9zKxH0Tsk9BLwEzM9Mv5fm+y7w18B7zS5EfSRwW0TcXz2hqekMbsO3zsdvSVotIrYCfgKcl5mvN7seQWa+m5n7UXsKzYyI8PKCJoqI44GXMvP+ZteitRycmQcAxwLnVpflNJXBbfjW+fgtSTXVNVQ/Aa7OzJ82ux71lZl/BO4EjmlyKe3uYODPq+uprgWOjIj/0dySBJCZL1SvLwHzqF0u1VQGt+Hz8VvSEFQXwV8OPJ6Z3252PaqJiIkRsW21vTnwMeCJ5lbV3jLzq5k5OTOnUvs35Y7M/EyTy2p7EbFltbCKiNgSOBpo+p0LDG7DlJmrgJ7Hbz0OXO/jt5ovIq4B7gV2i4hlEXFms2sSBwN/SW304KHq57hmFyUmAQsiYjG1/yM6PzO9/YS0tg7gnoj4HdAN/Dwzf9nkmrwdiCRJUikccZMkSSqEwU2SJKkQBjdJkqRCGNwkSZIKYXCTJEkqhMFNUtNFxEkRkRHxoSH2Py8itmh0XcMREadHxPc24P1TI6Lp94iS1NoMbpJawanAPdRuPjoU5wEtFdyGKyLGNbsGSeUxuElqqupZpgcDZ1IX3CLi8Ii4pW7/e9Wo1heBD1C7ieyC6tipEfFwRDwSEd+qe8/REXFvRDwQETdUn0VEPBcRX6vaH+4Z6YuIrSLiv1dtiyPiP63j/GdExFMRcVf1O/S0T4yIn0TEwurn4Kr97yLisoi4DbhqiH+f/SLit1U98yJiQtX+xYh4rGq/tmo7rO5mxw/23PVd0thhcJPUbCcCv8zMp4CVEXHAYJ0z81Jqzwc+IjOPiIgPAN8CjgT2A6ZHxIkRsQPwfwMfqx4SvQj4ct2pXq7afwB8pWq7EHgtM/fOzH2AOwY5/yTga9QC28eBPerO/Y/AdzJzOvCfgB/VHfsPwAmZ+Z+H+Pe5Cji/qudh4KKq/QJg/6r9c1XbV4BzqwfIfxT40xA/Q1IhHKqX1GynAt+ttq+t9h8YxvunA3dm5gqAiLgaOBRYRS1M/c/aY1PZlNpj0Xr0PPT+fuA/Vtsfo27ULzNfjYhDBzg/a7RfB+xad549qs8F2KZu9OvmzBxSoIqI9wHbZuZdVdNc4IZqezFwdUT8DPhZ1fY/gW9XNf40M5cN5XMklcPgJqlpImJ7aiNZe0VEAhsDGRF/TS141c8KjB/oNIO0z8/MUwc4/k71+i6r/7cwgDWfAzjQ+emnb4+NgA+vGdCqIPe/BznfcHySWoD8c+DCiNgzM78ZET8HjgN+GxEfy0wfIC+NIU6VSmqmWcBVmblTZk7NzCnA74FDgD9QG7XarBp5OqrufW8APSNY9wGHRcQOEbExtRG7u4DfAgdHxAcBImKLiNiVwd0GfL5np7qebKDz3wccHhHbR8QmwMmDnGe/YfxNemXma8CrEfHRqukvgbsiYiNgSmYuAP4a2BbYKiL+j8x8ODO/RW1qeEirdCWVw+AmqZlOBeat0fYT4D9n5vPA9VRTgsCDdX0uA34REQsy80Xgq8AC4HfAA5l5UzWFeTpwTUQsphbk1hVk/h6YUC1C+B216+gGOv+LwN9Rm379NX2nd78IdFYLBx5j9TVo67JbRCyr+zkZmA38P9XvsB/wdWojk/8jIh6u/i7fycw/AufV1f4n4BdD/FxJhYjMgUb6JUmS1EoccZMkSSqEwU2SJKkQBjdJkqRCGNwkSZIKYXCTJEkqhMFNkiSpEAY3SZKkQhjcJEmSCvH/A4y9keP/FDPMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='background')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

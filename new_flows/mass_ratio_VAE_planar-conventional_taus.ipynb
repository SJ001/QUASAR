{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import RealNVP, Planar\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnd = pd.read_hdf(\"/data/t3home000/spark/QUASAR/preprocessing/conventional_tau_rnd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mjj</th>\n",
       "      <th>j1 pT</th>\n",
       "      <th>j2 pT</th>\n",
       "      <th>Mj1</th>\n",
       "      <th>j1 tau21</th>\n",
       "      <th>j1 tau32</th>\n",
       "      <th>j1 tau43</th>\n",
       "      <th>j1 tau54</th>\n",
       "      <th>j1 tau65</th>\n",
       "      <th>j1 tau76</th>\n",
       "      <th>...</th>\n",
       "      <th>j2 tau87</th>\n",
       "      <th>j2 sqrt(tau^2_1)/tau^1_1</th>\n",
       "      <th>j2 n_trk</th>\n",
       "      <th>j2 M_trim</th>\n",
       "      <th>j2 M_prun</th>\n",
       "      <th>j2 M_mmdt</th>\n",
       "      <th>j2 M_sdb1</th>\n",
       "      <th>j2 M_sdb2</th>\n",
       "      <th>j2 M_sdm1</th>\n",
       "      <th>isSignal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2577.571899</td>\n",
       "      <td>1285.895950</td>\n",
       "      <td>1282.286017</td>\n",
       "      <td>98.677270</td>\n",
       "      <td>0.528903</td>\n",
       "      <td>0.788281</td>\n",
       "      <td>0.904471</td>\n",
       "      <td>0.881570</td>\n",
       "      <td>0.911651</td>\n",
       "      <td>0.869766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865858</td>\n",
       "      <td>1.895988</td>\n",
       "      <td>128.0</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>31.845136</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3807.507389</td>\n",
       "      <td>1334.493332</td>\n",
       "      <td>1306.137883</td>\n",
       "      <td>584.595432</td>\n",
       "      <td>0.345626</td>\n",
       "      <td>0.463461</td>\n",
       "      <td>0.865982</td>\n",
       "      <td>0.892948</td>\n",
       "      <td>0.843223</td>\n",
       "      <td>0.939763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934968</td>\n",
       "      <td>1.377217</td>\n",
       "      <td>348.0</td>\n",
       "      <td>395.226881</td>\n",
       "      <td>393.309512</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1710.965414</td>\n",
       "      <td>1072.462085</td>\n",
       "      <td>678.557182</td>\n",
       "      <td>159.597526</td>\n",
       "      <td>0.677692</td>\n",
       "      <td>0.690707</td>\n",
       "      <td>0.695322</td>\n",
       "      <td>0.823351</td>\n",
       "      <td>0.861655</td>\n",
       "      <td>0.909383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902637</td>\n",
       "      <td>1.887494</td>\n",
       "      <td>236.0</td>\n",
       "      <td>54.235070</td>\n",
       "      <td>41.967840</td>\n",
       "      <td>41.352112</td>\n",
       "      <td>51.721630</td>\n",
       "      <td>70.442364</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2603.379037</td>\n",
       "      <td>1284.020224</td>\n",
       "      <td>1217.031950</td>\n",
       "      <td>515.237299</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0.784454</td>\n",
       "      <td>0.860716</td>\n",
       "      <td>0.887306</td>\n",
       "      <td>0.885916</td>\n",
       "      <td>0.950761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924068</td>\n",
       "      <td>1.997360</td>\n",
       "      <td>352.0</td>\n",
       "      <td>81.842001</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>72.423677</td>\n",
       "      <td>84.480859</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294.162200</td>\n",
       "      <td>1205.343324</td>\n",
       "      <td>1087.658980</td>\n",
       "      <td>142.420213</td>\n",
       "      <td>0.507714</td>\n",
       "      <td>0.522686</td>\n",
       "      <td>0.904070</td>\n",
       "      <td>0.908468</td>\n",
       "      <td>0.918753</td>\n",
       "      <td>0.928911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906367</td>\n",
       "      <td>1.113248</td>\n",
       "      <td>204.0</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>99.817788</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mjj        j1 pT        j2 pT         Mj1  j1 tau21  j1 tau32  \\\n",
       "0  2577.571899  1285.895950  1282.286017   98.677270  0.528903  0.788281   \n",
       "1  3807.507389  1334.493332  1306.137883  584.595432  0.345626  0.463461   \n",
       "2  1710.965414  1072.462085   678.557182  159.597526  0.677692  0.690707   \n",
       "3  2603.379037  1284.020224  1217.031950  515.237299  0.091038  0.784454   \n",
       "4  3294.162200  1205.343324  1087.658980  142.420213  0.507714  0.522686   \n",
       "\n",
       "   j1 tau43  j1 tau54  j1 tau65  j1 tau76  ...  j2 tau87  \\\n",
       "0  0.904471  0.881570  0.911651  0.869766  ...  0.865858   \n",
       "1  0.865982  0.892948  0.843223  0.939763  ...  0.934968   \n",
       "2  0.695322  0.823351  0.861655  0.909383  ...  0.902637   \n",
       "3  0.860716  0.887306  0.885916  0.950761  ...  0.924068   \n",
       "4  0.904070  0.908468  0.918753  0.928911  ...  0.906367   \n",
       "\n",
       "   j2 sqrt(tau^2_1)/tau^1_1  j2 n_trk   j2 M_trim   j2 M_prun   j2 M_mmdt  \\\n",
       "0                  1.895988     128.0   42.162664   18.466533   18.466533   \n",
       "1                  1.377217     348.0  395.226881  393.309512  405.034096   \n",
       "2                  1.887494     236.0   54.235070   41.967840   41.352112   \n",
       "3                  1.997360     352.0   81.842001   60.307703   60.307703   \n",
       "4                  1.113248     204.0  103.456059   99.817788  103.456059   \n",
       "\n",
       "    j2 M_sdb1   j2 M_sdb2   j2 M_sdm1  isSignal  \n",
       "0   31.845136   42.162664    0.000000       0.0  \n",
       "1  405.034096  405.034096  405.034096       0.0  \n",
       "2   51.721630   70.442364   -0.000003       0.0  \n",
       "3   72.423677   84.480859    0.000003       0.0  \n",
       "4  103.456059  103.456059    0.000008       1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ROC':\n",
    "    dt = f_rnd.values\n",
    "else:\n",
    "    dt_PureBkg = dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (dt[:,3]>20) &(dt[:,19]>20) & (dt[:, 4] > 0)& (dt[:, 5] > 0)& (dt[:, 6] > 0)& (dt[:, 7] > 0)& (dt[:, 8] > 0) & (dt[:, 20] > 0)& (dt[:, 21] > 0)& (dt[:, 22] > 0)& (dt[:, 23] > 0)& (dt[:, 24] > 0) & (dt[:, 25] > 0)& (dt[:, 26] > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = dt[correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092753, 36)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4,5,6,7,8,9,10, 20, 21, 22, 23, 24, 25,26]:\n",
    "    #X[:,i] = (X[:,i]-np.mean(X[:,i]))/np.std(X[:,i])\n",
    "    dt[:,i] = ((dt[:,i]-np.min(dt[:,i]))/(np.max(dt[:,i])-np.min(dt[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13,19):\n",
    "    dt[:,i] = dt[:,i]/dt[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(29,35):\n",
    "    dt[:,i] = dt[:,i]/(dt[:,19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [11,27,12,28,3,19]:\n",
    "    dt[:,i] = (dt[:,i]-np.min(dt[:,i]))/(np.max(dt[:,i])-np.min(dt[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((dt[:,3:18], dt[:,19:34]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1092753, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQAklEQVR4nO3df4ylVX3H8ffHXfE3P5Qtobu0S+PadqVpxAliTKx1LSy0YUlqDaaW1WzcRMFaa9pC+wf4q9G0lUqD2K27FYx1odSUTcUSwo+YNl1kEIsulDIFhd2ijC5gW6K4+u0f9yDXZWbnWebOvXNn3q/kZp7nPOe595yd2fu55zw/bqoKSdLy9qxRN0CSNHqGgSTJMJAkGQaSJAwDSRKwctQNeKaOPfbYWrt27aibIUlj4/bbb/92Va2aadvYhsHatWuZnJwcdTMkaWwk+cZs25wmkiQZBpIkw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSY3wFsiRdfPHMyzp8jgwkSYaBJMkwkCRhGEiSMAwkSXg2kaQlwjOL5scwkDRWfKNfGE4TSZIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScJ7E0kaA96PaOE5MpAkGQaSJMNAkoRhIEnCMJAkYRhIkugYBknek2RPkq8l+WyS5yY5McmtSaaSXJXkiFb3OW19qm1f2/c8F7bye5Kc3le+sZVNJblg0J2UJB3anGGQZDXwu8BEVZ0ErADOAT4CXFJVLwUeAba0XbYAj7TyS1o9kqxv+70c2Ah8PMmKJCuAy4AzgPXAm1tdSXpGLr74qYe66TpNtBJ4XpKVwPOBh4DXA9e07VcAZ7flTW2dtn1DkrTynVX1/aq6H5gCTmmPqaq6r6qeAHa2upKkIZkzDKpqH/DnwAP0QuAx4Hbg0ao60KrtBVa35dXAg23fA63+S/rLD9pntvKnSbI1yWSSyenp6S79kyR10GWa6Bh6n9RPBH4aeAG9aZ6hq6ptVTVRVROrVq0aRRMkaUnqMk30BuD+qpquqh8AnwNeAxzdpo0A1gD72vI+4ASAtv0o4Dv95QftM1u5JGlIuoTBA8CpSZ7f5v43AHcBNwNvbHU2A9e25V1tnbb9pqqqVn5OO9voRGAd8CXgNmBdOzvpCHoHmXfNv2uSpK7mvGtpVd2a5Brgy8AB4A5gG/B5YGeSD7ay7W2X7cCnk0wB++m9uVNVe5JcTS9IDgDnVdUPAZKcD1xP70ylHVW1Z3BdlCTNJb0P7eNnYmKiJicnR90MSQtkUKeFenrpU5LcXlUTM23zCmRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kSsHLUDZCkJ1188ahbsHw5MpAkGQaSJMNAkoTHDCQtcf3HITwmMTtHBpIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJNExDJIcneSaJP+R5O4kr07y4iQ3JLm3/Tym1U2SS5NMJbkzycl9z7O51b83yea+8lcm+Wrb59IkGXxXJUmz6Toy+Bjwz1X1C8AvA3cDFwA3VtU64Ma2DnAGsK49tgKXAyR5MXAR8CrgFOCiJwOk1Xl7334b59ctSdLhmDMMkhwFvBbYDlBVT1TVo8Am4IpW7Qrg7La8CbiyenYDRyc5HjgduKGq9lfVI8ANwMa27ciq2l1VBVzZ91ySpCHoMjI4EZgG/jbJHUk+meQFwHFV9VCr803guLa8Gniwb/+9rexQ5XtnKH+aJFuTTCaZnJ6e7tB0SVIXXcJgJXAycHlVvQL4P56aEgKgfaKvwTfvJ1XVtqqaqKqJVatWLfTLSdKy0eX7DPYCe6vq1rZ+Db0w+FaS46vqoTbV83Dbvg84oW//Na1sH/C6g8pvaeVrZqgvaRnwOwYWhzlHBlX1TeDBJD/fijYAdwG7gCfPCNoMXNuWdwHntrOKTgUea9NJ1wOnJTmmHTg+Dbi+bftuklPbWUTn9j2XJGkIun7T2buAzyQ5ArgPeBu9ILk6yRbgG8CbWt3rgDOBKeDxVpeq2p/kA8Btrd77q2p/W34n8CngecAX2kOSNCSdwqCqvgJMzLBpwwx1CzhvlufZAeyYoXwSOKlLWyRJg+cVyJIkw0CSZBhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSSJ7l9uI0kD41ddLj6ODCRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRJeZyBpGTn4+gavd3iKIwNJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJOEVyJKGxKt9FzdHBpKk7mGQZEWSO5L8U1s/McmtSaaSXJXkiFb+nLY+1bav7XuOC1v5PUlO7yvf2MqmklwwuO5Jkro4nJHBu4G7+9Y/AlxSVS8FHgG2tPItwCOt/JJWjyTrgXOAlwMbgY+3gFkBXAacAawH3tzqSpKGpFMYJFkD/DrwybYe4PXANa3KFcDZbXlTW6dt39DqbwJ2VtX3q+p+YAo4pT2mquq+qnoC2NnqSpKGpOvI4C+BPwR+1NZfAjxaVQfa+l5gdVteDTwI0LY/1ur/uPygfWYrf5okW5NMJpmcnp7u2HRJ0lzmDIMkvwE8XFW3D6E9h1RV26pqoqomVq1aNermSNKS0eXU0tcAZyU5E3gucCTwMeDoJCvbp/81wL5Wfx9wArA3yUrgKOA7feVP6t9ntnJJ0hDMOTKoqgurak1VraV3APimqvpt4Gbgja3aZuDatryrrdO231RV1crPaWcbnQisA74E3Aasa2cnHdFeY9dAeidJ6mQ+F539EbAzyQeBO4DtrXw78OkkU8B+em/uVNWeJFcDdwEHgPOq6ocASc4HrgdWADuqas882iVJOkyHFQZVdQtwS1u+j96ZQAfX+R7wW7Ps/yHgQzOUXwdcdzhtkSQNjlcgS5IMA0mSYSBJwjCQJGEYSJIwDCRJ+OU2khaQX2gzPhwZSJIMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCThjeokDZg3pxtPjgwkSYaBJMlpIknLWP+U1nKf3nJkIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEl40ZmkAVjuF2wtBY4MJEmGgSTJMJAk0SEMkpyQ5OYkdyXZk+TdrfzFSW5Icm/7eUwrT5JLk0wluTPJyX3PtbnVvzfJ5r7yVyb5atvn0iRZiM5KkmbWZWRwAHhvVa0HTgXOS7IeuAC4sarWATe2dYAzgHXtsRW4HHrhAVwEvAo4BbjoyQBpdd7et9/G+XdNktTVnGFQVQ9V1Zfb8v8AdwOrgU3AFa3aFcDZbXkTcGX17AaOTnI8cDpwQ1Xtr6pHgBuAjW3bkVW1u6oKuLLvuSRJQ3BYxwySrAVeAdwKHFdVD7VN3wSOa8urgQf7dtvbyg5VvneG8plef2uSySST09PTh9N0SdIhdA6DJC8E/gH4var6bv+29om+Bty2p6mqbVU1UVUTq1atWuiXk6Rlo1MYJHk2vSD4TFV9rhV/q03x0H4+3Mr3ASf07b6mlR2qfM0M5ZKkIZnzCuR2Zs924O6q+mjfpl3AZuDD7ee1feXnJ9lJ72DxY1X1UJLrgT/tO2h8GnBhVe1P8t0kp9KbfjoX+KsB9E3SAvKq46Wly+0oXgP8DvDVJF9pZX9MLwSuTrIF+AbwprbtOuBMYAp4HHgbQHvT/wBwW6v3/qra35bfCXwKeB7whfaQJA3JnGFQVf8CzHbe/4YZ6hdw3izPtQPYMUP5JHDSXG2RJC0Mr0CWJBkGkiTDQJKEYSBJwi+3kXQYPJ106XJkIEkyDCRJhoEkCcNAkoRhIEnCs4kkCfjJM6WW41lThoGkQ1qOb4zLkdNEkiTDQJJkGEiSMAwkSXgAWdIMPGi8/DgykCQZBpIkw0CShMcMJDUeJ1jeHBlIkgwDSZJhIEnCYwbSsuZxAj3JkYEkyZGBtNw4GtBMHBlIkgwDSZLTRNKS57TQ4VuOX4HpyECS5MhAWoqWy6dZDY5hIC0RBoDmwzCQxpgBoEExDKQxYwBoIRgG0iLlm76GadGEQZKNwMeAFcAnq+rDI26SNBS+6S9uy+U000URBklWAJcBvwbsBW5Lsquq7hpty6RulvKbhJaHRREGwCnAVFXdB5BkJ7AJMAwE+GarxWEpjxIWSxisBh7sW98LvOrgSkm2Alvb6v8muecZvt6xwLef4b7jyj4vfcutvzDCPr/vfaN4VWB+ff7Z2TYsljDopKq2Advm+zxJJqtqYgBNGhv2eelbbv0F+zxIi+V2FPuAE/rW17QySdIQLJYwuA1Yl+TEJEcA5wC7RtwmSVo2FsU0UVUdSHI+cD29U0t3VNWeBXzJeU81jSH7vPQtt/6CfR6YVNVCPK8kaYwslmkiSdIIGQaSpKUdBkk2JrknyVSSC2bY/pwkV7XttyZZO/xWDk6H/v5+kruS3JnkxiSznnM8Lubqc1+930xSScb+NMQufU7ypva73pPk74bdxkHr8Lf9M0luTnJH+/s+cxTtHJQkO5I8nORrs2xPkkvbv8edSU6e94tW1ZJ80DsQ/V/AzwFHAP8OrD+ozjuBT7Tlc4CrRt3uBe7vrwLPb8vvGOf+du1zq/ci4IvAbmBi1O0ewu95HXAHcExb/6lRt3sIfd4GvKMtrwe+Pup2z7PPrwVOBr42y/YzgS8AAU4Fbp3vay7lkcGPb3FRVU8AT97iot8m4Iq2fA2wIUmG2MZBmrO/VXVzVT3eVnfTu55jnHX5HQN8APgI8L1hNm6BdOnz24HLquoRgKp6eMhtHLQufS7gyLZ8FPDfQ2zfwFXVF4H9h6iyCbiyenYDRyc5fj6vuZTDYKZbXKyerU5VHQAeA14ylNYNXpf+9ttC75PFOJuzz234fEJVfX6YDVtAXX7PLwNeluRfk+xudwQeZ136fDHwliR7geuAdw2naSNzuP/f57QorjPQcCV5CzAB/Mqo27KQkjwL+Cjw1hE3ZdhW0psqeh290d8Xk/xSVT060lYtrDcDn6qqv0jyauDTSU6qqh+NumHjYimPDLrc4uLHdZKspDe8/M5QWjd4nW7pkeQNwJ8AZ1XV94fUtoUyV59fBJwE3JLk6/TmVneN+UHkLr/nvcCuqvpBVd0P/Ce9cBhXXfq8BbgaoKr+DXguvRu6LVUDv4XPUg6DLre42AVsbstvBG6qdnRmDM3Z3ySvAP6aXhCM+zwyzNHnqnqsqo6tqrVVtZbecZKzqmpyNM0diC5/1/9Ib1RAkmPpTRvdN8xGDliXPj8AbABI8ov0wmB6qK0crl3Aue2solOBx6rqofk84ZKdJqpZbnGR5P3AZFXtArbTG05O0TtYc87oWjw/Hfv7Z8ALgb9vx8kfqKqzRtboeerY5yWlY5+vB05LchfwQ+APqmpcR7xd+/xe4G+SvIfeweS3jvEHO5J8ll6gH9uOg1wEPBugqj5B77jImcAU8Djwtnm/5hj/e0mSBmQpTxNJkjoyDCRJhoEkyTCQJGEYSJIwDCRJGAaSJOD/AU6tpoByjOWkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0,1,101)\n",
    "plt.hist(X[:,22],bins,alpha=0.5,color='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt[:,-1]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(X[bkg_idx])\n",
    "\n",
    "total_PureBkg_selection = total_PureBkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([992924, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_PureBkg_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(30, 64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(64, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(64, 30),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = Planar(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 30\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 4\n",
    "Z_DIM = 6\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            #writer.add_scalar('loss/{}/ELBO'.format(split), loss.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/reconstruction'.format(split), loss_recons.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/KL'.format(split), kl_div.item(), n_steps)\n",
    "\n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE_NF(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=30, out_features=64, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Linear(in_features=64, out_features=48, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=48, out_features=12, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=48, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Linear(in_features=48, out_features=64, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=64, out_features=30, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      "  (flows): NormalizingFlowModel(\n",
      "    (flows): ModuleList(\n",
      "      (0): Planar()\n",
      "      (1): Planar()\n",
      "      (2): Planar()\n",
      "      (3): Planar()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "reduce failed to synchronize: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-708188fc2d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-063378879e2c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss_recons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_recons\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl_div\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2065\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: reduce failed to synchronize: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "BEST_LOSS = 99999999\n",
    "LAST_SAVED = -1\n",
    "PATIENCE_COUNT = 0\n",
    "PATIENCE_LIMIT = 5\n",
    "for epoch in range(1, 1000):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        PATIENCE_COUNT = 0\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        if mode == 'ROC':\n",
    "            torch.save(model.state_dict(),\"/data/t3home000/spark/QUASAR/weights/____bkg_vae_NF_planar_RND_conventionaltau.h5\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_PureBkg_22var.h5\")\n",
    "    else:\n",
    "        PATIENCE_COUNT += 1\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "        if PATIENCE_COUNT > 5:\n",
    "            print(\"Patience Limit Reached\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_RND_conventionaltau.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt):\n",
    "    print(dt.shape)\n",
    "    \n",
    "    #for i in index_list:\n",
    "    #    print(i)\n",
    "    #    dt[:,i] = (dt[:,i]-np.mean(dt[:,i]))/np.std(dt[:,i])\n",
    "  \n",
    "    \n",
    "    total_in = torch.tensor(dt)\n",
    "    #total_in_train_x_1 = total_in.t()[0:6].t()\n",
    "    #total_in_train_x_3 = total_in.t()[7:13].t()\n",
    "    total_in_selection = total_in\n",
    "    #z_mu, z_var  = model.enc(total_in_selection.float().cuda())\n",
    "    #x_sample, z_mu, z_var = model(total_in_selection.float().cuda())\n",
    "    #std = torch.exp(z_var / 2)\n",
    "    #eps = torch.randn_like(std)\n",
    "    #x_sample = eps.mul(std).add_(z_mu)\n",
    "    #decoded_bkg = model.dec(x_sample)\n",
    "    #recon_loss = np.zeros(len(dt),dtype=np.float)\n",
    "    #for i in range(len(dt)):\n",
    "    #    recon_loss[i] = F.binary_cross_entropy(x_sample[i].float().cuda(), total_in_selection[i].float().cuda(), size_average=False).data.cpu().numpy()\n",
    "    \n",
    "    #loss_bkg = torch.mean((x_sample.float().cuda()-total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "         #reconstruction loss\n",
    "        #x_sample, z_mu, z_var = model(total_in_selection.float().cuda())\n",
    "        #recon_loss = F.binary_cross_entropy(x_sample, total_in_selection.float().cuda(), size_average=False, reduce=None)\n",
    "        \n",
    "\n",
    "        #kl divergence loss\n",
    "        #kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        #total loss\n",
    "        #loss = recon_loss + kl_loss\n",
    "        loss = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.tensor(X[bkg_idx]).float().cuda())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(992924, 30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j1 M_sdb1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fd580de5ba8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0,1,100)\n",
    "bins.shape\n",
    "column = 16\n",
    "print(f_rnd.columns[column])\n",
    "plt.hist(X[bkg_idx,column],bins,alpha=0.5,color='b');\n",
    "plt.hist(out[:,column],bins,alpha=0.5,color='r');\n",
    "plt.axvline(np.mean(X[bkg_idx,column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 94)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[signal_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992924, 30)\n",
      "(99829, 30)\n"
     ]
    }
   ],
   "source": [
    "loss_bkg = get_loss(X[bkg_idx])\n",
    "loss_sig = get_loss(X[signal_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,0.5,1100)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr(sigloss,bkgloss,aetype='sig'):\n",
    "    bins = np.linspace(0,50,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss<cut)[0].shape[0]/len(bkgloss))\n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss>cut)[0].shape[0]/len(bkgloss))\n",
    "    return tpr,fpr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_tpr, bkg_fpr = get_tpr_fpr(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_tpr.npy',bkg_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bkg_fpr,bkg_tpr,label='Bkg NFlowVAE-Planar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall(sigloss,bkgloss,aetype='bkg'):\n",
    "    bins = np.linspace(0,100,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    precision = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss<cut)[0].shape[0])/(np.where(bkgloss<cut)[0].shape[0]+np.where(sigloss<cut)[0].shape[0]))\n",
    "            \n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss>cut)[0].shape[0])/(np.where(bkgloss>cut)[0].shape[0]+np.where(sigloss>cut)[0].shape[0]))\n",
    "    return precision,tpr      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall = get_precision_recall(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_22var_sigloss.npy',loss_sig)\n",
    "np.save('NFLOWVAE_PlanarNEW_22var_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_precision.npy',precision)\n",
    "np.save('NFLOWVAE_PlanarNEW_recall.npy',recall)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_tpr.npy',bkg_tpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_sigloss.npy',loss_sig)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows = [1,2,3,4,5,6]\n",
    "zdim = [1,2,3,4,5]\n",
    "\n",
    "for N_flows in flows:\n",
    "    for Z_DIM in zdim:\n",
    "        model = VAE_NF(N_FLOWS, Z_DIM).cuda()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "        BEST_LOSS = 99999\n",
    "        LAST_SAVED = -1\n",
    "        PATIENCE_COUNT = 0\n",
    "        PATIENCE_LIMIT = 5\n",
    "        for epoch in range(1, N_EPOCHS):\n",
    "            print(\"Epoch {}:\".format(epoch))\n",
    "            train()\n",
    "            cur_loss = evaluate()\n",
    "\n",
    "            if cur_loss <= BEST_LOSS:\n",
    "                PATIENCE_COUNT = 0\n",
    "                BEST_LOSS = cur_loss\n",
    "                LAST_SAVED = epoch\n",
    "                print(\"Saving model!\")\n",
    "                if mode == 'ROC':\n",
    "                    torch.save(model.state_dict(),f\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_RND_22var_z{Z_DIM}_f{N_FLOWS}.h5\")\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), f\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_PureBkg_22var_z{Z_DIM}_f{N_FLOWS}.h5\")\n",
    "            else:\n",
    "                PATIENCE_COUNT += 1\n",
    "                print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "                if PATIENCE_COUNT > 3:\n",
    "                    print(\"Patience Limit Reached\")\n",
    "                    break \n",
    "                    \n",
    "        loss_bkg = get_loss(dt_PureBkg[bkg_idx])\n",
    "        loss_sig = get_loss(dt_PureBkg[signal_idx])\n",
    "        np.save(f'NFLOWVAE_PlanarNEW_22var_z{Z_DIM}_f{N_flows}_sigloss.npy',loss_sig)\n",
    "        np.save(f'NFLOWVAE_PlanarNEW_22var_z{Z_DIM}_f{N_flows}_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

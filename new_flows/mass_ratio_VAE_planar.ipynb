{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import RealNVP, Planar\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_PureBkg = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_pureBkg.h5\")\n",
    "dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg)\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(22, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 22),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = Planar(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 2\n",
    "Z_DIM = 3\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            #writer.add_scalar('loss/{}/ELBO'.format(split), loss.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/reconstruction'.format(split), loss_recons.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/KL'.format(split), kl_div.item(), n_steps)\n",
    "\n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -382.0795 Time: 3.209 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -384.5019 Time: 3.204 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -384.2560 Time: 3.210 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 4:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -384.5752 Time: 3.209 s\n",
      "Saving model!\n",
      "Epoch 5:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -383.5045 Time: 3.212 s\n",
      "Not saving model! Last saved: 4\n",
      "Epoch 6:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -383.1235 Time: 3.984 s\n",
      "Not saving model! Last saved: 4\n",
      "Epoch 7:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -381.4383 Time: 3.190 s\n",
      "Not saving model! Last saved: 4\n",
      "Epoch 8:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -381.2356 Time: 3.298 s\n",
      "Not saving model! Last saved: 4\n",
      "Epoch 9:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -379.9078 Time: 3.266 s\n",
      "Not saving model! Last saved: 4\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar.h5\")\n",
    "    else:\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]-\n",
    "                       total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass(inputstring):\n",
    "\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='background')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_hdf(\"Nsubjettiness_mjj.h5\")\n",
    "dt = f.values\n",
    "idx = dt[:,15]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]\n",
    "data_bkg = torch.tensor(dt[bkg_idx])\n",
    "data_signal = torch.tensor(dt[signal_idx])\n",
    "data_train_x_1 = data_bkg.t()[0:6].t()\n",
    "data_train_x_2 = data_bkg.t()[7:13].t()\n",
    "data_test_bkg = torch.cat((data_train_x_1,data_train_x_2),dim=1)\n",
    "data_train_x_1 = data_signal.t()[0:6].t()\n",
    "data_train_x_2 = data_signal.t()[7:13].t()\n",
    "data_test_signal = torch.cat((data_train_x_1,data_train_x_2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = torch.mean((model(data_test_bkg.float().cuda())[0]-data_test_bkg.float().cuda())**2,dim=1).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sig = torch.mean((model(data_test_signal.float().cuda())[0]-data_test_signal.float().cuda())**2,dim=1).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt_in):\n",
    "\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_RandD.h5\")\n",
    "dt = f.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt[:,27]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = get_loss(dt[bkg_idx,:])\n",
    "loss_sig = get_loss(dt[signal_idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr(sigloss,bkgloss,aetype='sig'):\n",
    "    bins = np.linspace(0,50,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss<cut)[0].shape[0]/len(bkgloss))\n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss>cut)[0].shape[0]/len(bkgloss))\n",
    "    return tpr,fpr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_tpr, bkg_fpr = get_tpr_fpr(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_Planar2_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_Planar2_bkgAE_tpr.npy',bkg_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4129b4f7b8>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(bkg_fpr,bkg_tpr,label='Bkg NFlowVAE-Planar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

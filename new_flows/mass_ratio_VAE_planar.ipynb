{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import RealNVP, Planar\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nvidia-smi` not found.\n"
     ]
    }
   ],
   "source": [
    "%nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'ROC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_rnd = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_RandD.h5\")\n",
    "f_PureBkg = pd.read_hdf(\"/data/t3home000/spark/LHCOlympics/data/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mjj</th>\n",
       "      <th>Mj1</th>\n",
       "      <th>j1 tau21</th>\n",
       "      <th>j1 tau32</th>\n",
       "      <th>j1 tau43</th>\n",
       "      <th>j1 sqrt(tau^2_1)/tau^1_1</th>\n",
       "      <th>j1 n_trk</th>\n",
       "      <th>j1 pT1</th>\n",
       "      <th>j1 M_trim</th>\n",
       "      <th>j1 M_prun</th>\n",
       "      <th>...</th>\n",
       "      <th>j2 sqrt(tau^2_1)/tau^1_1</th>\n",
       "      <th>j2 n_trk</th>\n",
       "      <th>j2 pT1</th>\n",
       "      <th>j2 M_trim</th>\n",
       "      <th>j2 M_prun</th>\n",
       "      <th>j2 M_mmdt</th>\n",
       "      <th>j2 M_sdb1</th>\n",
       "      <th>j2 M_sdb2</th>\n",
       "      <th>j2 M_sdm1</th>\n",
       "      <th>isSignal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2577.571899</td>\n",
       "      <td>98.677270</td>\n",
       "      <td>0.528903</td>\n",
       "      <td>0.788281</td>\n",
       "      <td>0.904471</td>\n",
       "      <td>4.241889</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1285.895950</td>\n",
       "      <td>18.881765</td>\n",
       "      <td>9.797733</td>\n",
       "      <td>...</td>\n",
       "      <td>1.895988</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1282.286017</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>18.466533</td>\n",
       "      <td>31.845136</td>\n",
       "      <td>42.162664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3807.507389</td>\n",
       "      <td>584.595432</td>\n",
       "      <td>0.345626</td>\n",
       "      <td>0.463461</td>\n",
       "      <td>0.865982</td>\n",
       "      <td>1.069972</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1334.493332</td>\n",
       "      <td>556.665923</td>\n",
       "      <td>562.607897</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377217</td>\n",
       "      <td>348.0</td>\n",
       "      <td>1306.137883</td>\n",
       "      <td>395.226881</td>\n",
       "      <td>393.309512</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>405.034096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1710.965414</td>\n",
       "      <td>159.597526</td>\n",
       "      <td>0.677692</td>\n",
       "      <td>0.690707</td>\n",
       "      <td>0.695322</td>\n",
       "      <td>1.310040</td>\n",
       "      <td>332.0</td>\n",
       "      <td>678.557182</td>\n",
       "      <td>144.351550</td>\n",
       "      <td>142.366275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.887494</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1072.462085</td>\n",
       "      <td>54.235070</td>\n",
       "      <td>41.967840</td>\n",
       "      <td>41.352112</td>\n",
       "      <td>51.721630</td>\n",
       "      <td>70.442364</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2603.379037</td>\n",
       "      <td>515.237299</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0.784454</td>\n",
       "      <td>0.860716</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>248.0</td>\n",
       "      <td>1284.020224</td>\n",
       "      <td>501.564320</td>\n",
       "      <td>506.727622</td>\n",
       "      <td>...</td>\n",
       "      <td>1.997360</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1217.031950</td>\n",
       "      <td>81.842001</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>60.307703</td>\n",
       "      <td>72.423677</td>\n",
       "      <td>84.480859</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3294.162200</td>\n",
       "      <td>142.420213</td>\n",
       "      <td>0.507714</td>\n",
       "      <td>0.522686</td>\n",
       "      <td>0.904070</td>\n",
       "      <td>1.853319</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1087.658980</td>\n",
       "      <td>129.146700</td>\n",
       "      <td>36.160229</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113248</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1205.343324</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>99.817788</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>103.456059</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mjj         Mj1  j1 tau21  j1 tau32  j1 tau43  \\\n",
       "0  2577.571899   98.677270  0.528903  0.788281  0.904471   \n",
       "1  3807.507389  584.595432  0.345626  0.463461  0.865982   \n",
       "2  1710.965414  159.597526  0.677692  0.690707  0.695322   \n",
       "3  2603.379037  515.237299  0.091038  0.784454  0.860716   \n",
       "4  3294.162200  142.420213  0.507714  0.522686  0.904070   \n",
       "\n",
       "   j1 sqrt(tau^2_1)/tau^1_1  j1 n_trk       j1 pT1   j1 M_trim   j1 M_prun  \\\n",
       "0                  4.241889     136.0  1285.895950   18.881765    9.797733   \n",
       "1                  1.069972     320.0  1334.493332  556.665923  562.607897   \n",
       "2                  1.310040     332.0   678.557182  144.351550  142.366275   \n",
       "3                  1.102743     248.0  1284.020224  501.564320  506.727622   \n",
       "4                  1.853319     220.0  1087.658980  129.146700   36.160229   \n",
       "\n",
       "   ...  j2 sqrt(tau^2_1)/tau^1_1  j2 n_trk       j2 pT1   j2 M_trim  \\\n",
       "0  ...                  1.895988     128.0  1282.286017   42.162664   \n",
       "1  ...                  1.377217     348.0  1306.137883  395.226881   \n",
       "2  ...                  1.887494     236.0  1072.462085   54.235070   \n",
       "3  ...                  1.997360     352.0  1217.031950   81.842001   \n",
       "4  ...                  1.113248     204.0  1205.343324  103.456059   \n",
       "\n",
       "    j2 M_prun   j2 M_mmdt   j2 M_sdb1   j2 M_sdb2   j2 M_sdm1  isSignal  \n",
       "0   18.466533   18.466533   31.845136   42.162664    0.000000       0.0  \n",
       "1  393.309512  405.034096  405.034096  405.034096  405.034096       0.0  \n",
       "2   41.967840   41.352112   51.721630   70.442364   -0.000003       0.0  \n",
       "3   60.307703   60.307703   72.423677   84.480859    0.000003       0.0  \n",
       "4   99.817788  103.456059  103.456059  103.456059    0.000008       1.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_rnd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mjj</th>\n",
       "      <th>Mj1</th>\n",
       "      <th>j1 tau21</th>\n",
       "      <th>j1 tau32</th>\n",
       "      <th>j1 tau43</th>\n",
       "      <th>j1 sqrt(tau^2_1)/tau^1_1</th>\n",
       "      <th>j1 n_trk</th>\n",
       "      <th>j1 pT1</th>\n",
       "      <th>j1 M_trim</th>\n",
       "      <th>j1 M_prun</th>\n",
       "      <th>...</th>\n",
       "      <th>j2 tau43</th>\n",
       "      <th>j2 sqrt(tau^2_1)/tau^1_1</th>\n",
       "      <th>j2 n_trk</th>\n",
       "      <th>j2 pT1</th>\n",
       "      <th>j2 M_trim</th>\n",
       "      <th>j2 M_prun</th>\n",
       "      <th>j2 M_mmdt</th>\n",
       "      <th>j2 M_sdb1</th>\n",
       "      <th>j2 M_sdb2</th>\n",
       "      <th>j2 M_sdm1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2308.313028</td>\n",
       "      <td>128.326132</td>\n",
       "      <td>0.189019</td>\n",
       "      <td>0.911555</td>\n",
       "      <td>0.849721</td>\n",
       "      <td>1.308323</td>\n",
       "      <td>144.0</td>\n",
       "      <td>697.776317</td>\n",
       "      <td>127.413126</td>\n",
       "      <td>127.413126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774201</td>\n",
       "      <td>2.003320</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1405.544993</td>\n",
       "      <td>36.389206</td>\n",
       "      <td>30.116799</td>\n",
       "      <td>31.486846</td>\n",
       "      <td>31.486846</td>\n",
       "      <td>36.389206</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2433.658374</td>\n",
       "      <td>168.702659</td>\n",
       "      <td>0.471191</td>\n",
       "      <td>0.668339</td>\n",
       "      <td>0.835098</td>\n",
       "      <td>2.122381</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1218.344352</td>\n",
       "      <td>168.702659</td>\n",
       "      <td>99.211013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748061</td>\n",
       "      <td>1.591575</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1181.231345</td>\n",
       "      <td>86.360518</td>\n",
       "      <td>78.302729</td>\n",
       "      <td>83.267629</td>\n",
       "      <td>87.636863</td>\n",
       "      <td>87.636863</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2687.853262</td>\n",
       "      <td>259.775966</td>\n",
       "      <td>0.272282</td>\n",
       "      <td>0.834496</td>\n",
       "      <td>0.905154</td>\n",
       "      <td>2.443252</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1278.656676</td>\n",
       "      <td>249.529914</td>\n",
       "      <td>27.569778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876479</td>\n",
       "      <td>2.694852</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1370.333269</td>\n",
       "      <td>142.759911</td>\n",
       "      <td>17.207589</td>\n",
       "      <td>5.411157</td>\n",
       "      <td>161.894075</td>\n",
       "      <td>161.894075</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3020.510484</td>\n",
       "      <td>227.093270</td>\n",
       "      <td>0.681522</td>\n",
       "      <td>0.636388</td>\n",
       "      <td>0.861016</td>\n",
       "      <td>1.940825</td>\n",
       "      <td>384.0</td>\n",
       "      <td>999.484105</td>\n",
       "      <td>201.818360</td>\n",
       "      <td>47.193330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743863</td>\n",
       "      <td>1.343559</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1526.551452</td>\n",
       "      <td>116.511073</td>\n",
       "      <td>109.874007</td>\n",
       "      <td>109.874007</td>\n",
       "      <td>109.874007</td>\n",
       "      <td>133.288161</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2285.694841</td>\n",
       "      <td>118.372552</td>\n",
       "      <td>0.456816</td>\n",
       "      <td>0.713677</td>\n",
       "      <td>0.644830</td>\n",
       "      <td>1.873234</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1391.822493</td>\n",
       "      <td>60.537433</td>\n",
       "      <td>59.034145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919837</td>\n",
       "      <td>1.776008</td>\n",
       "      <td>256.0</td>\n",
       "      <td>618.616945</td>\n",
       "      <td>86.433637</td>\n",
       "      <td>101.312752</td>\n",
       "      <td>113.277482</td>\n",
       "      <td>113.277482</td>\n",
       "      <td>113.277482</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mjj         Mj1  j1 tau21  j1 tau32  j1 tau43  \\\n",
       "0  2308.313028  128.326132  0.189019  0.911555  0.849721   \n",
       "1  2433.658374  168.702659  0.471191  0.668339  0.835098   \n",
       "2  2687.853262  259.775966  0.272282  0.834496  0.905154   \n",
       "3  3020.510484  227.093270  0.681522  0.636388  0.861016   \n",
       "4  2285.694841  118.372552  0.456816  0.713677  0.644830   \n",
       "\n",
       "   j1 sqrt(tau^2_1)/tau^1_1  j1 n_trk       j1 pT1   j1 M_trim   j1 M_prun  \\\n",
       "0                  1.308323     144.0   697.776317  127.413126  127.413126   \n",
       "1                  2.122381     196.0  1218.344352  168.702659   99.211013   \n",
       "2                  2.443252     212.0  1278.656676  249.529914   27.569778   \n",
       "3                  1.940825     384.0   999.484105  201.818360   47.193330   \n",
       "4                  1.873234     112.0  1391.822493   60.537433   59.034145   \n",
       "\n",
       "   ...  j2 tau43  j2 sqrt(tau^2_1)/tau^1_1  j2 n_trk       j2 pT1   j2 M_trim  \\\n",
       "0  ...  0.774201                  2.003320      76.0  1405.544993   36.389206   \n",
       "1  ...  0.748061                  1.591575     284.0  1181.231345   86.360518   \n",
       "2  ...  0.876479                  2.694852     212.0  1370.333269  142.759911   \n",
       "3  ...  0.743863                  1.343559     252.0  1526.551452  116.511073   \n",
       "4  ...  0.919837                  1.776008     256.0   618.616945   86.433637   \n",
       "\n",
       "    j2 M_prun   j2 M_mmdt   j2 M_sdb1   j2 M_sdb2  j2 M_sdm1  \n",
       "0   30.116799   31.486846   31.486846   36.389206  -0.000011  \n",
       "1   78.302729   83.267629   87.636863   87.636863  -0.000003  \n",
       "2   17.207589    5.411157  161.894075  161.894075   0.000002  \n",
       "3  109.874007  109.874007  109.874007  133.288161  -0.000005  \n",
       "4  101.312752  113.277482  113.277482  113.277482   0.000001  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_PureBkg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ROC':\n",
    "    dt_PureBkg = f_rnd.values\n",
    "else:\n",
    "    dt_PureBkg = dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dt_PureBkg[:,27]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg[bkg_idx])\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "#total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "#total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "#total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_3),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 12])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_PureBkg_selection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(12, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 12),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = Planar(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Instance¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 2\n",
    "Z_DIM = 3\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            #writer.add_scalar('loss/{}/ELBO'.format(split), loss.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/reconstruction'.format(split), loss_recons.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/KL'.format(split), kl_div.item(), n_steps)\n",
    "\n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE_NF(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=96, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Linear(in_features=96, out_features=48, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=48, out_features=6, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=48, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=True)\n",
      "    (2): Linear(in_features=48, out_features=96, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=True)\n",
      "    (4): Linear(in_features=96, out_features=12, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      "  (flows): NormalizingFlowModel(\n",
      "    (flows): ModuleList(\n",
      "      (0): Planar()\n",
      "      (1): Planar()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]/home/spark/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/49 [00:10<08:21, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -88.0074 Time: 3.388 s\n",
      "Saving model!\n",
      "Epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/49 [00:20<08:08, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -117.6705 Time: 3.362 s\n",
      "Saving model!\n",
      "Epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/49 [00:31<07:56, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -133.6069 Time: 3.375 s\n",
      "Saving model!\n",
      "Epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/49 [00:41<07:44, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -139.9612 Time: 3.379 s\n",
      "Saving model!\n",
      "Epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 5/49 [00:51<07:33, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.3448 Time: 3.389 s\n",
      "Saving model!\n",
      "Epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/49 [01:01<07:22, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.5402 Time: 3.360 s\n",
      "Saving model!\n",
      "Epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 7/49 [01:12<07:13, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.0321 Time: 3.366 s\n",
      "Saving model!\n",
      "Epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 8/49 [01:22<07:02, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.3213 Time: 3.369 s\n",
      "Saving model!\n",
      "Epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/49 [01:32<06:51, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.3518 Time: 3.370 s\n",
      "Saving model!\n",
      "Epoch 10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 10/49 [01:42<06:40, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.4174 Time: 3.372 s\n",
      "Saving model!\n",
      "Epoch 11:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/49 [01:53<06:30, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.4601 Time: 3.346 s\n",
      "Saving model!\n",
      "Epoch 12:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/49 [02:03<06:19, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.3636 Time: 3.345 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 13:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 13/49 [02:13<06:08, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -142.2379 Time: 3.345 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 14:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▊       | 14/49 [02:23<05:58, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.9579 Time: 3.341 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 15:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 15/49 [02:34<05:48, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.8243 Time: 3.401 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 16:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 16/49 [02:44<05:38, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.5994 Time: 3.349 s\n",
      "Not saving model! Last saved: 11\n",
      "Epoch 17:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 16/49 [02:54<06:00, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -141.4941 Time: 3.349 s\n",
      "Not saving model! Last saved: 11\n",
      "Patience Limit Reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "PATIENCE_COUNT = 0\n",
    "PATIENCE_LIMIT = 5\n",
    "for epoch in tqdm.tqdm(range(1, N_EPOCHS)):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        PATIENCE_COUNT = 0\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        if mode == 'ROC':\n",
    "            torch.save(model.state_dict(),\"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_RND.h5\")\n",
    "        else:\n",
    "            torch.save(model.state_dict(), \"/data/t3home000/spark/QUASAR/weights/bkg_vae_NF_planar_PureBkg.h5\")\n",
    "    else:\n",
    "        PATIENCE_COUNT += 1\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))\n",
    "        if PATIENCE_COUNT > 5:\n",
    "            print(\"Patience Limit Reached\")\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    #total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_3),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]-\n",
    "                       total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass(inputstring):\n",
    "\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='background')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_hdf(\"Nsubjettiness_mjj.h5\")\n",
    "dt = f.values\n",
    "idx = dt[:,15]\n",
    "bkg_idx = np.where(idx==0)[0]\n",
    "signal_idx = np.where(idx==1)[0]\n",
    "data_bkg = torch.tensor(dt[bkg_idx])\n",
    "data_signal = torch.tensor(dt[signal_idx])\n",
    "data_train_x_1 = data_bkg.t()[0:6].t()\n",
    "data_train_x_2 = data_bkg.t()[7:13].t()\n",
    "data_test_bkg = torch.cat((data_train_x_1,data_train_x_2),dim=1)\n",
    "data_train_x_1 = data_signal.t()[0:6].t()\n",
    "data_train_x_2 = data_signal.t()[7:13].t()\n",
    "data_test_signal = torch.cat((data_train_x_1,data_train_x_2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = torch.mean((model(data_test_bkg.float().cuda())[0]-data_test_bkg.float().cuda())**2,dim=1).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sig = torch.mean((model(data_test_signal.float().cuda())[0]-data_test_signal.float().cuda())**2,dim=1).data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt_in):\n",
    "\n",
    "    #dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    #dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    #dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    #dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    #dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    #dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    #dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    #dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    #dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    #dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    #dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    #dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    #dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    #dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    #dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    #dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    #dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    #dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    #dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    #dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    #dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    #dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    #total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_3),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dt):\n",
    "    \n",
    "    #dt[:,0] = (dt[:,0]-np.mean(dt[:,0]))/np.std(dt[:,0])\n",
    "    #dt[:,1] = (dt[:,1]-np.mean(dt[:,1]))/np.std(dt[:,1])\n",
    "    #dt[:,2] = (dt[:,2]-np.mean(dt[:,2]))/np.std(dt[:,2])\n",
    "    #dt[:,3] = (dt[:,3]-np.mean(dt[:,3]))/np.std(dt[:,3])\n",
    "    #dt[:,4] = (dt[:,4]-np.mean(dt[:,4]))/np.std(dt[:,4])\n",
    "    #dt[:,5] = (dt[:,5]-np.mean(dt[:,5]))/np.std(dt[:,5])\n",
    "\n",
    "    #dt[:,7] = (dt[:,7]-np.mean(dt[:,7]))/np.std(dt[:,7])\n",
    "    #dt[:,8] = (dt[:,8]-np.mean(dt[:,8]))/np.std(dt[:,8])\n",
    "    #dt[:,9] = (dt[:,9]-np.mean(dt[:,9]))/np.std(dt[:,9])\n",
    "    #dt[:,10] = (dt[:,10]-np.mean(dt[:,10]))/np.std(dt[:,10])\n",
    "    #dt[:,11] = (dt[:,11]-np.mean(dt[:,11]))/np.std(dt[:,11])\n",
    "    #dt[:,12] = (dt[:,12]-np.mean(dt[:,12]))/np.std(dt[:,12])\n",
    "\n",
    "  \n",
    "    \n",
    "    total_in = torch.tensor(dt)\n",
    "    total_in_train_x_1 = total_in.t()[0:6].t()\n",
    "    #total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[7:13].t()\n",
    "    #total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    #total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_3),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_bkg = get_loss(dt_PureBkg[bkg_idx])\n",
    "loss_sig = get_loss(dt_PureBkg[signal_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(loss_bkg,bins=bins,alpha=0.3,color='b',label='bkg')\n",
    "plt.hist(loss_sig,bins=bins,alpha=0.3,color='r',label='sig')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_fpr(sigloss,bkgloss,aetype='sig'):\n",
    "    bins = np.linspace(0,50,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss<cut)[0].shape[0]/len(bkgloss))\n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            fpr.append(np.where(bkgloss>cut)[0].shape[0]/len(bkgloss))\n",
    "    return tpr,fpr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_tpr, bkg_fpr = get_tpr_fpr(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_tpr.npy',bkg_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bkg_fpr,bkg_tpr,label='Bkg NFlowVAE-Planar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall(sigloss,bkgloss,aetype='bkg'):\n",
    "    bins = np.linspace(0,100,1001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    precision = []\n",
    "    for cut in bins:\n",
    "        if aetype == 'sig':\n",
    "            tpr.append(np.where(sigloss<cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss<cut)[0].shape[0])/(np.where(bkgloss<cut)[0].shape[0]+np.where(sigloss<cut)[0].shape[0]))\n",
    "            \n",
    "        if aetype == 'bkg':\n",
    "            tpr.append(np.where(sigloss>cut)[0].shape[0]/len(sigloss))\n",
    "            precision.append((np.where(sigloss>cut)[0].shape[0])/(np.where(bkgloss>cut)[0].shape[0]+np.where(sigloss>cut)[0].shape[0]))\n",
    "    return precision,tpr      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall = get_precision_recall(loss_sig,loss_bkg,aetype='bkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_sigloss.npy',loss_sig)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('NFLOWVAE_PlanarNEW_precision.npy',precision)\n",
    "np.save('NFLOWVAE_PlanarNEW_recall.npy',recall)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_fpr.npy',bkg_fpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgAE_tpr.npy',bkg_tpr)\n",
    "np.save('NFLOWVAE_PlanarNEW_sigloss.npy',loss_sig)\n",
    "np.save('NFLOWVAE_PlanarNEW_bkgloss.npy',loss_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

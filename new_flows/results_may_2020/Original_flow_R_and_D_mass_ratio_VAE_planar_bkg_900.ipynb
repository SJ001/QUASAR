{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import RealNVP\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")\n",
    "f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_bkg.h5\")\n",
    "dt_PureBkg = f_PureBkg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg)\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "#bkgAE_dataset = utils.TensorDataset(data_train_x,data_train_x) \n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quadro M4000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanarFlow(nn.Module):\n",
    "    def __init__(self, D):\n",
    "        super().__init__()\n",
    "        self.D = D\n",
    "\n",
    "    def forward(self, z, lamda):\n",
    "        '''\n",
    "        z - latents from prev layer\n",
    "        lambda - Flow parameters (b, w, u)\n",
    "        b - scalar\n",
    "        w - vector\n",
    "        u - vector\n",
    "        '''\n",
    "        b = lamda[:, :1]\n",
    "        w, u = lamda[:, 1:].chunk(2, dim=1)\n",
    "\n",
    "        # Forward\n",
    "        # f(z) = z + u tanh(w^T z + b)\n",
    "        transf = F.tanh(\n",
    "            z.unsqueeze(1).bmm(w.unsqueeze(2))[:, 0] + b\n",
    "        )\n",
    "        f_z = z + u * transf\n",
    "\n",
    "        # Inverse\n",
    "        # psi_z = tanh' (w^T z + b) w\n",
    "        psi_z = (1 - transf ** 2) * w\n",
    "        log_abs_det_jacobian = torch.log(\n",
    "            (1 + psi_z.unsqueeze(1).bmm(u.unsqueeze(2))).abs()\n",
    "        )\n",
    "\n",
    "        return f_z, log_abs_det_jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.flows = nn.ModuleList([PlanarFlow(D) for i in range(K)])\n",
    "\n",
    "    def forward(self, z_k, flow_params):\n",
    "        # ladj -> log abs det jacobian\n",
    "        sum_ladj = 0\n",
    "        for i, flow in enumerate(self.flows):\n",
    "            z_k, ladj_k = flow(z_k, flow_params[i])\n",
    "            sum_ladj += ladj_k\n",
    "\n",
    "        return z_k, sum_ladj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(22, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2 + K * (D * 2 + 1))\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 22),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.flows = NormalizingFlow(K, D)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "        flow_params = enc[:, 2 * self.dim:].chunk(self.K, dim=1)\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Construct more expressive posterior with NF\n",
    "        z_k, sum_ladj = self.flows(z, flow_params)\n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "N_EPOCHS = 80\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "MODEL = 'VAE-NF'  # VAE-NF | VAE\n",
    "\n",
    "N_FLOWS = 2\n",
    "Z_DIM = 3\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL == 'VAE-NF':\n",
    "    model = VAE_NF(N_FLOWS, Z_DIM).cuda()\n",
    "else:\n",
    "    model = VAE(Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "        #writer.add_scalar('loss/train/ELBO', loss.item(), n_steps)\n",
    "        #writer.add_scalar('loss/train/reconstruction', loss_recons.item(), n_steps)\n",
    "        #writer.add_scalar('loss/train/KL', kl_div.item(), n_steps)\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            #writer.add_scalar('loss/{}/ELBO'.format(split), loss.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/reconstruction'.format(split), loss_recons.item(), n_steps)\n",
    "            #writer.add_scalar('loss/{}/KL'.format(split), kl_div.item(), n_steps)\n",
    "\n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: -299.5107 Time: 4.746 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -356.9413 Time: 4.737 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -365.8344 Time: 5.118 s\n",
      "Saving model!\n",
      "Epoch 4:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -376.9025 Time: 4.745 s\n",
      "Saving model!\n",
      "Epoch 5:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -380.8666 Time: 4.723 s\n",
      "Saving model!\n",
      "Epoch 6:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -380.9237 Time: 5.339 s\n",
      "Saving model!\n",
      "Epoch 7:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -380.0405 Time: 4.710 s\n",
      "Not saving model! Last saved: 6\n",
      "Epoch 8:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -382.4693 Time: 4.772 s\n",
      "Saving model!\n",
      "Epoch 9:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -378.3412 Time: 4.755 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 10:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -372.2831 Time: 4.720 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 11:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.9089 Time: 4.897 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 12:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.8061 Time: 4.730 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 13:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -376.6892 Time: 4.696 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 14:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -378.2366 Time: 4.883 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 15:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -378.7945 Time: 4.696 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 16:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -379.8409 Time: 4.883 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 17:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -377.3382 Time: 4.695 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 18:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -377.0733 Time: 4.702 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 19:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -376.9404 Time: 4.691 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 20:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -377.1860 Time: 4.691 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 21:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -376.9638 Time: 4.998 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 22:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -377.5876 Time: 4.710 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 23:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -377.1668 Time: 4.992 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 24:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -371.6263 Time: 4.763 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 25:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -372.2842 Time: 5.383 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 26:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -371.4692 Time: 5.010 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 27:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -371.5774 Time: 5.521 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 28:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.3464 Time: 4.952 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 29:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.5882 Time: 4.729 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 30:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.9342 Time: 4.719 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 31:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.7248 Time: 4.703 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 32:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.3934 Time: 4.693 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 33:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.2397 Time: 4.696 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 34:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.6222 Time: 4.726 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 35:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -367.3092 Time: 5.299 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 36:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -367.7191 Time: 5.428 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 37:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.0590 Time: 4.776 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 38:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.6602 Time: 4.739 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 39:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.5545 Time: 4.801 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 40:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.6904 Time: 5.223 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 41:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.5224 Time: 4.736 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 42:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.6654 Time: 4.811 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 43:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.4620 Time: 4.759 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 44:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -365.8616 Time: 4.746 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 45:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -365.7446 Time: 4.807 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 46:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -365.7459 Time: 4.778 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 47:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -367.3773 Time: 4.788 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 48:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.0062 Time: 4.792 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 49:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.2875 Time: 4.764 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 50:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -368.4363 Time: 4.784 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 51:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -367.6683 Time: 5.539 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 52:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.5543 Time: 4.796 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 53:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.3635 Time: 5.455 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 54:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.1881 Time: 4.744 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 55:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.5128 Time: 5.499 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 56:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.5331 Time: 4.808 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 57:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -371.2624 Time: 5.001 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 58:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.0020 Time: 4.819 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 59:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.4137 Time: 4.875 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 60:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.1093 Time: 4.785 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 61:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.0062 Time: 4.784 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 62:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.1500 Time: 4.794 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 63:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -369.6660 Time: 4.806 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 64:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -365.9575 Time: 4.675 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 65:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.5220 Time: 4.732 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 66:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -367.1822 Time: 4.701 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 67:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -364.5937 Time: 4.718 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 68:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -367.3885 Time: 4.718 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 69:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.3884 Time: 4.738 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 70:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.1999 Time: 4.739 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 71:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.7898 Time: 4.722 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 72:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -366.5819 Time: 5.480 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 73:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.0977 Time: 4.746 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 74:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -371.7708 Time: 4.699 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 75:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -370.7039 Time: 4.895 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 76:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -364.1604 Time: 4.746 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 77:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -365.8734 Time: 4.726 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 78:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -363.5316 Time: 4.715 s\n",
      "Not saving model! Last saved: 8\n",
      "Epoch 79:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -363.7976 Time: 4.720 s\n",
      "Not saving model! Last saved: 8\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        torch.save(model.state_dict(), \"lhc_weights/original_bkg_vae_NF_planar_rd.h5\")\n",
    "    else:\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]-\n",
    "                       total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass(inputstring):\n",
    "\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass = get_mass(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_pureBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "#plt.hist(purebkgloss[np.where((purebkgmass>6000) & (purebkgmass<7000))[0]],bins=bins,label='background',color=\"blue\");\n",
    "#plt.hist(bb2loss[np.where((bb2mass>6000) & (bb2mass<7000))[0]],bins=bins,label='Blackbox2',histtype='step',color=\"red\");\n",
    "#plt.semilogy()\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='background')\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "# plt.savefig(\"/data/t3home000/spark/LHCOlympics/plots/NF_bkgAE_autoencoder_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import NSF_AR\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_signal.h5\")\n",
    "dt_PureBkg = f_PureBkg.values\n",
    "# # Select the signal only from R&D\n",
    "# dt_PureBkg = dt_PureBkg[np.where(dt_PureBkg[:,-1]==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_signal = f_PureBkg.loc[f_PureBkg['isSignal'] == 0]\n",
    "# data_signal.to_hdf('../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_bkg.h5',key=\"bkg\")\n",
    "# f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_bkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg)\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(22, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 22),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = NSF_AR(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 40\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 4\n",
    "Z_DIM = 3\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -254.3305 Time: 5.203 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -254.3562 Time: 5.313 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -253.8645 Time: 5.156 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 4:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -253.7251 Time: 6.031 s\n",
      "Not saving model! Last saved: 2\n",
      "Epoch 5:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -255.2907 Time: 5.670 s\n",
      "Saving model!\n",
      "Epoch 6:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -255.1665 Time: 5.672 s\n",
      "Not saving model! Last saved: 5\n",
      "Epoch 7:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -255.4430 Time: 5.387 s\n",
      "Saving model!\n",
      "Epoch 8:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -254.3179 Time: 5.189 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 9:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -254.7339 Time: 5.307 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 10:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -253.9474 Time: 5.380 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 11:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -253.7134 Time: 5.667 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 12:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -252.9016 Time: 5.914 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 13:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -251.1367 Time: 5.200 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 14:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -250.3534 Time: 5.495 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 15:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -249.1131 Time: 5.317 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 16:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -247.5669 Time: 5.438 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 17:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -245.8779 Time: 5.425 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 18:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -244.8113 Time: 5.539 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 19:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -243.2100 Time: 5.245 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 20:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -241.0445 Time: 5.861 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 21:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -240.5936 Time: 5.526 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 22:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.5650 Time: 5.417 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 23:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -241.5702 Time: 5.644 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 24:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.8545 Time: 5.494 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 25:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.5965 Time: 5.702 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 26:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.0061 Time: 5.519 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 27:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.5352 Time: 5.353 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 28:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -241.6748 Time: 5.187 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 29:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -241.6300 Time: 5.296 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 30:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.0336 Time: 5.690 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 31:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -241.9891 Time: 5.555 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 32:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -242.4916 Time: 5.431 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 33:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -241.8072 Time: 5.676 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 34:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -244.3039 Time: 5.151 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 35:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -244.4193 Time: 5.281 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 36:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -243.8986 Time: 5.674 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 37:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -245.5614 Time: 5.515 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 38:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -247.0653 Time: 5.657 s\n",
      "Not saving model! Last saved: 7\n",
      "Epoch 39:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -248.0019 Time: 5.171 s\n",
      "Not saving model! Last saved: 7\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        torch.save(model.state_dict(), \"lhc_weights/bkg_vae_NF_NSF_AR_train_on_signal.h5\")\n",
    "    else:\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 7.94 GiB total capacity; 261.50 KiB already allocated; 61.94 MiB free; 7.74 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7d027ecaeae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbb2mass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb2mmdt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb2mmdt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb2prun1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbb2prun2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb2loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mass_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpurebkgmass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurebkgmmdt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurebkgmmdt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurebkgprun1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpurebkgprun2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpurebkgloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mass_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_signal.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e7da04781609>\u001b[0m in \u001b[0;36mget_mass_and_loss\u001b[0;34m(inputstring)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss_total_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_in_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mtotal_in_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mf_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 7.94 GiB total capacity; 261.50 KiB already allocated; 61.94 MiB free; 7.74 MiB cached)"
     ]
    }
   ],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_signal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='signal',weights=np.ones(len(purebkgloss))*10)\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

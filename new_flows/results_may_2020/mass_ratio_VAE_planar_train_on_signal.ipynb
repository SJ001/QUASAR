{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.utils.data as utils\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from argparse import ArgumentParser\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "from flows import Planar\n",
    "from models import NormalizingFlowModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_signal.h5\")\n",
    "dt_PureBkg = f_PureBkg.values\n",
    "# # Select the signal only from R&D\n",
    "# dt_PureBkg = dt_PureBkg[np.where(dt_PureBkg[:,-1]==1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_signal = f_PureBkg.loc[f_PureBkg['isSignal'] == 0]\n",
    "# data_signal.to_hdf('../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_bkg.h5',key=\"bkg\")\n",
    "# f_PureBkg = pd.read_hdf(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_bkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_PureBkg[:,1] = (dt_PureBkg[:,1]-np.mean(dt_PureBkg[:,1]))/np.std(dt_PureBkg[:,1])\n",
    "dt_PureBkg[:,2] = (dt_PureBkg[:,2]-np.mean(dt_PureBkg[:,2]))/np.std(dt_PureBkg[:,2])\n",
    "dt_PureBkg[:,3] = (dt_PureBkg[:,3]-np.mean(dt_PureBkg[:,3]))/np.std(dt_PureBkg[:,3])\n",
    "dt_PureBkg[:,4] = (dt_PureBkg[:,4]-np.mean(dt_PureBkg[:,4]))/np.std(dt_PureBkg[:,4])\n",
    "dt_PureBkg[:,5] = (dt_PureBkg[:,5]-np.mean(dt_PureBkg[:,5]))/np.std(dt_PureBkg[:,5])\n",
    "dt_PureBkg[:,6] = (dt_PureBkg[:,6]-np.mean(dt_PureBkg[:,6]))/np.std(dt_PureBkg[:,6])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,8] = (dt_PureBkg[:,8]-np.mean(dt_PureBkg[:,8]))/np.std(dt_PureBkg[:,8])\n",
    "dt_PureBkg[:,9] = (dt_PureBkg[:,9]-np.mean(dt_PureBkg[:,9]))/np.std(dt_PureBkg[:,9])\n",
    "dt_PureBkg[:,10] = (dt_PureBkg[:,10]-np.mean(dt_PureBkg[:,10]))/np.std(dt_PureBkg[:,10])\n",
    "dt_PureBkg[:,11] = (dt_PureBkg[:,11]-np.mean(dt_PureBkg[:,11]))/np.std(dt_PureBkg[:,11])\n",
    "dt_PureBkg[:,12] = (dt_PureBkg[:,12]-np.mean(dt_PureBkg[:,12]))/np.std(dt_PureBkg[:,12])\n",
    "\n",
    "dt_PureBkg[:,14] = (dt_PureBkg[:,14]-np.mean(dt_PureBkg[:,14]))/np.std(dt_PureBkg[:,14])\n",
    "dt_PureBkg[:,15] = (dt_PureBkg[:,15]-np.mean(dt_PureBkg[:,15]))/np.std(dt_PureBkg[:,15])\n",
    "dt_PureBkg[:,16] = (dt_PureBkg[:,16]-np.mean(dt_PureBkg[:,16]))/np.std(dt_PureBkg[:,16])\n",
    "dt_PureBkg[:,17] = (dt_PureBkg[:,17]-np.mean(dt_PureBkg[:,17]))/np.std(dt_PureBkg[:,17])\n",
    "dt_PureBkg[:,18] = (dt_PureBkg[:,18]-np.mean(dt_PureBkg[:,18]))/np.std(dt_PureBkg[:,18])\n",
    "dt_PureBkg[:,19] = (dt_PureBkg[:,19]-np.mean(dt_PureBkg[:,19]))/np.std(dt_PureBkg[:,19])\n",
    "\n",
    "\n",
    "dt_PureBkg[:,21] = (dt_PureBkg[:,21]-np.mean(dt_PureBkg[:,21]))/np.std(dt_PureBkg[:,21])\n",
    "dt_PureBkg[:,22] = (dt_PureBkg[:,22]-np.mean(dt_PureBkg[:,22]))/np.std(dt_PureBkg[:,22])\n",
    "dt_PureBkg[:,23] = (dt_PureBkg[:,23]-np.mean(dt_PureBkg[:,23]))/np.std(dt_PureBkg[:,23])\n",
    "dt_PureBkg[:,24] = (dt_PureBkg[:,24]-np.mean(dt_PureBkg[:,24]))/np.std(dt_PureBkg[:,24])\n",
    "dt_PureBkg[:,25] = (dt_PureBkg[:,25]-np.mean(dt_PureBkg[:,25]))/np.std(dt_PureBkg[:,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_PureBkg = torch.tensor(dt_PureBkg)\n",
    "total_PureBkg_train_x_1 = total_PureBkg.t()[1:7].t()\n",
    "total_PureBkg_train_x_2 = total_PureBkg.t()[8:13].t()\n",
    "total_PureBkg_train_x_3 = total_PureBkg.t()[14:20].t()\n",
    "total_PureBkg_train_x_4 = total_PureBkg.t()[21:26].t()\n",
    "\n",
    "total_PureBkg_selection = torch.cat((total_PureBkg_train_x_1,total_PureBkg_train_x_2,total_PureBkg_train_x_3,total_PureBkg_train_x_4),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000\n",
    "bkgAE_train_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs, shuffle=True) \n",
    "bkgAE_test_iterator = utils.DataLoader(total_PureBkg_selection, batch_size=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_NF(nn.Module):\n",
    "    def __init__(self, K, D):\n",
    "        super().__init__()\n",
    "        self.dim = D\n",
    "        self.K = K\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(22, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 48),\n",
    "            nn.LeakyReLU(True),            \n",
    "            nn.Linear(48, D * 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(D, 48),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(48, 96),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(96, 22),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        flow_init = Planar(dim=D)\n",
    "        flows_init = [flow_init for _ in range(K)]\n",
    "        prior = MultivariateNormal(torch.zeros(D).cuda(), torch.eye(D).cuda())\n",
    "        self.flows = NormalizingFlowModel(prior, flows_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run Encoder and get NF params\n",
    "        enc = self.encoder(x)\n",
    "        mu = enc[:, :self.dim]\n",
    "        log_var = enc[:, self.dim: self.dim * 2]\n",
    "\n",
    "        # Re-parametrize\n",
    "        sigma = (log_var * .5).exp()\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        # Construct more expressive posterior with NF\n",
    "        \n",
    "        z_k, _, sum_ladj = self.flows(z)\n",
    "        \n",
    "        kl_div = kl_div / x.size(0) - sum_ladj.mean()  # mean over batch\n",
    "\n",
    "        # Run Decoder\n",
    "        x_prime = self.decoder(z_k)\n",
    "        return x_prime, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating InstanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 40\n",
    "PRINT_INTERVAL = 2000\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "\n",
    "N_FLOWS = 4\n",
    "Z_DIM = 3\n",
    "\n",
    "n_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE_NF(N_FLOWS, Z_DIM).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global n_steps\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, x in enumerate(bkgAE_train_iterator):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x = x.float().cuda()\n",
    "\n",
    "        x_tilde, kl_div = model(x)\n",
    "        loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "        loss = loss_recons + kl_div\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append([loss_recons.item(), kl_div.item()])\n",
    "\n",
    "        if (batch_idx + 1) % PRINT_INTERVAL == 0:\n",
    "            print('\\tIter [{}/{} ({:.0f}%)]\\tLoss: {} Time: {:5.3f} ms/batch'.format(\n",
    "                batch_idx * len(x), 50000,\n",
    "                PRINT_INTERVAL * batch_idx / 50000,\n",
    "                np.asarray(train_loss)[-PRINT_INTERVAL:].mean(0),\n",
    "                1000 * (time.time() - start_time)\n",
    "            ))\n",
    "\n",
    "        n_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split='valid'):\n",
    "    global n_steps\n",
    "    start_time = time.time()\n",
    "    val_loss = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, x in enumerate(bkgAE_test_iterator):\n",
    "            \n",
    "            x = x.float().cuda()\n",
    "\n",
    "            x_tilde, kl_div = model(x)\n",
    "            loss_recons = F.binary_cross_entropy(x_tilde, x, size_average=False) / x.size(0)\n",
    "            loss = loss_recons + kl_div\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    print('\\nEvaluation Completed ({})!\\tLoss: {:5.4f} Time: {:5.3f} s'.format(\n",
    "        split,\n",
    "        np.asarray(val_loss).mean(0),\n",
    "        time.time() - start_time\n",
    "    ))\n",
    "    return np.asarray(val_loss).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Completed (valid)!\tLoss: 11.3295 Time: 0.697 s\n",
      "Saving model!\n",
      "Epoch 2:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -34.1575 Time: 0.661 s\n",
      "Saving model!\n",
      "Epoch 3:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -89.3790 Time: 0.722 s\n",
      "Saving model!\n",
      "Epoch 4:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -100.9440 Time: 0.666 s\n",
      "Saving model!\n",
      "Epoch 5:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -112.7565 Time: 0.731 s\n",
      "Saving model!\n",
      "Epoch 6:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -128.9934 Time: 0.670 s\n",
      "Saving model!\n",
      "Epoch 7:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -152.0926 Time: 0.752 s\n",
      "Saving model!\n",
      "Epoch 8:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -161.7371 Time: 0.721 s\n",
      "Saving model!\n",
      "Epoch 9:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -168.5055 Time: 0.667 s\n",
      "Saving model!\n",
      "Epoch 10:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -174.4474 Time: 0.737 s\n",
      "Saving model!\n",
      "Epoch 11:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -179.4142 Time: 0.668 s\n",
      "Saving model!\n",
      "Epoch 12:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -183.7349 Time: 0.709 s\n",
      "Saving model!\n",
      "Epoch 13:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -189.6601 Time: 0.722 s\n",
      "Saving model!\n",
      "Epoch 14:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -191.9486 Time: 0.714 s\n",
      "Saving model!\n",
      "Epoch 15:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -196.0841 Time: 0.674 s\n",
      "Saving model!\n",
      "Epoch 16:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -199.4647 Time: 0.717 s\n",
      "Saving model!\n",
      "Epoch 17:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -202.3121 Time: 0.758 s\n",
      "Saving model!\n",
      "Epoch 18:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -205.0387 Time: 0.721 s\n",
      "Saving model!\n",
      "Epoch 19:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -207.7247 Time: 0.716 s\n",
      "Saving model!\n",
      "Epoch 20:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -208.9383 Time: 0.714 s\n",
      "Saving model!\n",
      "Epoch 21:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -212.2844 Time: 0.714 s\n",
      "Saving model!\n",
      "Epoch 22:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -212.6635 Time: 0.774 s\n",
      "Saving model!\n",
      "Epoch 23:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -214.9164 Time: 0.674 s\n",
      "Saving model!\n",
      "Epoch 24:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -216.8739 Time: 0.729 s\n",
      "Saving model!\n",
      "Epoch 25:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -220.3807 Time: 0.788 s\n",
      "Saving model!\n",
      "Epoch 26:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -223.3019 Time: 0.712 s\n",
      "Saving model!\n",
      "Epoch 27:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -224.4011 Time: 0.724 s\n",
      "Saving model!\n",
      "Epoch 28:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -225.1499 Time: 0.782 s\n",
      "Saving model!\n",
      "Epoch 29:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -226.9058 Time: 0.725 s\n",
      "Saving model!\n",
      "Epoch 30:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -228.4723 Time: 0.712 s\n",
      "Saving model!\n",
      "Epoch 31:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -228.2057 Time: 0.725 s\n",
      "Not saving model! Last saved: 30\n",
      "Epoch 32:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -229.1444 Time: 0.757 s\n",
      "Saving model!\n",
      "Epoch 33:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -232.0040 Time: 0.726 s\n",
      "Saving model!\n",
      "Epoch 34:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -232.7436 Time: 0.742 s\n",
      "Saving model!\n",
      "Epoch 35:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -233.9998 Time: 0.732 s\n",
      "Saving model!\n",
      "Epoch 36:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -235.6017 Time: 0.709 s\n",
      "Saving model!\n",
      "Epoch 37:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -236.6931 Time: 0.774 s\n",
      "Saving model!\n",
      "Epoch 38:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -237.7761 Time: 0.738 s\n",
      "Saving model!\n",
      "Epoch 39:\n",
      "\n",
      "Evaluation Completed (valid)!\tLoss: -237.6949 Time: 0.691 s\n",
      "Not saving model! Last saved: 38\n"
     ]
    }
   ],
   "source": [
    "BEST_LOSS = 99999\n",
    "LAST_SAVED = -1\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    print(\"Epoch {}:\".format(epoch))\n",
    "    train()\n",
    "    cur_loss = evaluate()\n",
    "\n",
    "    if cur_loss <= BEST_LOSS:\n",
    "        BEST_LOSS = cur_loss\n",
    "        LAST_SAVED = epoch\n",
    "        print(\"Saving model!\")\n",
    "        torch.save(model.state_dict(), \"lhc_weights/bkg_vae_NF_planar_train_on_signal.h5\")\n",
    "    else:\n",
    "        print(\"Not saving model! Last saved: {}\".format(LAST_SAVED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_and_loss(inputstring):\n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    dt_in[:,1] = (dt_in[:,1]-np.mean(dt_in[:,1]))/np.std(dt_in[:,1])\n",
    "    dt_in[:,2] = (dt_in[:,2]-np.mean(dt_in[:,2]))/np.std(dt_in[:,2])\n",
    "    dt_in[:,3] = (dt_in[:,3]-np.mean(dt_in[:,3]))/np.std(dt_in[:,3])\n",
    "    dt_in[:,4] = (dt_in[:,4]-np.mean(dt_in[:,4]))/np.std(dt_in[:,4])\n",
    "    dt_in[:,5] = (dt_in[:,5]-np.mean(dt_in[:,5]))/np.std(dt_in[:,5])\n",
    "    dt_in[:,6] = (dt_in[:,6]-np.mean(dt_in[:,6]))/np.std(dt_in[:,6])\n",
    "\n",
    "    dt_in[:,8] = (dt_in[:,8]-np.mean(dt_in[:,8]))/np.std(dt_in[:,8])\n",
    "    dt_in[:,9] = (dt_in[:,9]-np.mean(dt_in[:,9]))/np.std(dt_in[:,9])\n",
    "    dt_in[:,10] = (dt_in[:,10]-np.mean(dt_in[:,10]))/np.std(dt_in[:,10])\n",
    "    dt_in[:,11] = (dt_in[:,11]-np.mean(dt_in[:,11]))/np.std(dt_in[:,11])\n",
    "    dt_in[:,12] = (dt_in[:,12]-np.mean(dt_in[:,12]))/np.std(dt_in[:,12])\n",
    "\n",
    "    dt_in[:,14] = (dt_in[:,14]-np.mean(dt_in[:,14]))/np.std(dt_in[:,14])\n",
    "    dt_in[:,15] = (dt_in[:,15]-np.mean(dt_in[:,15]))/np.std(dt_in[:,15])\n",
    "    dt_in[:,16] = (dt_in[:,16]-np.mean(dt_in[:,16]))/np.std(dt_in[:,16])\n",
    "    dt_in[:,17] = (dt_in[:,17]-np.mean(dt_in[:,17]))/np.std(dt_in[:,17])\n",
    "    dt_in[:,18] = (dt_in[:,18]-np.mean(dt_in[:,18]))/np.std(dt_in[:,18])\n",
    "    dt_in[:,19] = (dt_in[:,19]-np.mean(dt_in[:,19]))/np.std(dt_in[:,19])\n",
    "    \n",
    "    dt_in[:,21] = (dt_in[:,21]-np.mean(dt_in[:,21]))/np.std(dt_in[:,21])\n",
    "    dt_in[:,22] = (dt_in[:,22]-np.mean(dt_in[:,22]))/np.std(dt_in[:,22])\n",
    "    dt_in[:,23] = (dt_in[:,23]-np.mean(dt_in[:,23]))/np.std(dt_in[:,23])\n",
    "    dt_in[:,24] = (dt_in[:,24]-np.mean(dt_in[:,24]))/np.std(dt_in[:,24])\n",
    "    dt_in[:,25] = (dt_in[:,25]-np.mean(dt_in[:,25]))/np.std(dt_in[:,25])   \n",
    "    \n",
    "    total_in = torch.tensor(dt_in)\n",
    "    total_in_train_x_1 = total_in.t()[1:7].t()\n",
    "    total_in_train_x_2 = total_in.t()[8:13].t()\n",
    "    total_in_train_x_3 = total_in.t()[14:20].t()\n",
    "    total_in_train_x_4 = total_in.t()[21:26].t()\n",
    "    total_in_selection = torch.cat((total_in_train_x_1,total_in_train_x_2,total_in_train_x_3,total_in_train_x_4),dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss_total_in = torch.mean((model(total_in_selection.float().cuda())[0]- total_in_selection.float().cuda())**2,dim=1).data.cpu().numpy()\n",
    "    \n",
    "    f_in = pd.read_hdf(inputstring)\n",
    "    dt_in = f_in.values\n",
    "    \n",
    "    return dt_in[:,0], dt_in[:,10], dt_in[:,23], dt_in[:,9], dt_in[:,22], loss_total_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2mass, bb2mmdt1, bb2mmdt2, bb2prun1,bb2prun2, bb2loss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_BB1.h5\")\n",
    "purebkgmass, purebkgmmdt1, purebkgmmdt2, purebkgprun1,purebkgprun2, purebkgloss = get_mass_and_loss(\"../../../2_lhc/LHC_Olympics2020/processing/test_dataset/MassRatio_RandD_signal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "bins = np.linspace(0,5,1100)\n",
    "plt.hist(bb2loss,bins=bins,alpha=0.3,color='b',label='blackbox1')\n",
    "plt.hist(purebkgloss,bins=bins,alpha=0.3,color='r',label='signal',weights=np.ones(len(purebkgloss))*10)\n",
    "plt.xlabel(r'Autoencoder Loss')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
